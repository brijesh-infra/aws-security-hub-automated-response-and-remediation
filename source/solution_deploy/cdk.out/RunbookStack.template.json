{
 "Description": "(SO0111R) AWS Security Hub Automated Response & Remediation Remediation Runbooks, v1.50.mybuild",
 "AWSTemplateFormatVersion": "2010-09-09",
 "Resources": {
  "SHARRCreateCloudTrailMultiRegionTrail": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-CreateCloudTrailMultiRegionTrail",
    "Content": "description: |\n  ### Document Name - SHARR-CreateCloudTrailMultiRegionTrail\n  ## What does this document do?\n  Creates a multi-region trail with KMS encryption and enables CloudTrail\n  Note: this remediation will create a NEW trail.\n  \n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * KMSKeyArn (from SSM): Arn of the KMS key to be used to encrypt data\n\n  ## Security Standards / Controls\n  * AFSBP v1.0.0:   CloudTrail.1\n  * CIS v1.2.0:     2.1\n  * PCI:            CloudTrail.2\n\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  KMSKeyArn:\n    type: String\n    default: >-\n      {{ssm:/Solutions/SO0111/CMK_REMEDIATION_ARN}}\n    description: The ARN of the KMS key created by SHARR for this remediation\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):kms:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\d):\\d{12}:(?:(?:alias/[A-Za-z0-9/-_])|(?:key/(?i:[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12})))$'\n  AWSPartition:\n    type: String\n    default: 'aws'\n    description: 'Partition for creation of ARNs.'\n    allowedValues:\n      - aws\n      - aws-cn\n      - aws-us-gov\n\noutputs:\n  - Remediation.Output\n\nmainSteps:\n  - \n    name: CreateLoggingBucket\n    action: 'aws:executeScript'\n    outputs:\n      - Name: LoggingBucketName\n        Selector: $.Payload.logging_bucket\n        Type: String\n    inputs:\n      InputPayload: \n        account: '{{global:ACCOUNT_ID}}'\n        region: '{{global:REGION}}'\n        kms_key_arn: '{{KMSKeyArn}}'        \n      Runtime: python3.8\n      Handler: create_logging_bucket\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        ERROR_CREATING_BUCKET = 'Error creating bucket '\n        \n        def connect_to_s3(boto_config):\n            return boto3.client('s3', config=boto_config)\n        \n        def create_logging_bucket(event, context):\n        \n            boto_config = Config(\n                retries ={\n                    'mode': 'standard'\n                }\n            )\n            s3 = connect_to_s3(boto_config)\n        \n            kms_key_arn = event['kms_key_arn']\n            aws_account = event['account']\n            aws_region = event['region']\n            bucket_name = 'so0111-access-logs-' + aws_region + '-' + aws_account\n        \n            if create_bucket(s3, bucket_name, aws_region) == 'bucket_exists':\n                return {\"logging_bucket\": bucket_name}\n            encrypt_bucket(s3, bucket_name, kms_key_arn)\n            put_access_block(s3, bucket_name)\n            put_bucket_acl(s3, bucket_name)\n        \n            return {\"logging_bucket\": bucket_name}\n        \n        def create_bucket(s3, bucket_name, aws_region):\n            try:\n                kwargs = {\n                    'Bucket': bucket_name,\n                    'ACL': 'private'\n                }\n                if aws_region != 'us-east-1':\n                    kwargs['CreateBucketConfiguration'] = {\n                        'LocationConstraint': aws_region\n                    }\n        \n                s3.create_bucket(**kwargs)\n        \n            except ClientError as ex:\n                exception_type = ex.response['Error']['Code']\n                # bucket already exists - return\n                if exception_type in [\"BucketAlreadyExists\", \"BucketAlreadyOwnedByYou\"]:\n                    print('Bucket ' + bucket_name + ' already exists')\n                    return 'bucket_exists'\n                else:\n                    print(ex)\n                    exit(ERROR_CREATING_BUCKET + bucket_name)\n            except Exception as e:\n                print(e)\n                exit(ERROR_CREATING_BUCKET + bucket_name)\n        \n        def encrypt_bucket(s3, bucket_name, kms_key_arn):\n            try:\n                s3.put_bucket_encryption(\n                    Bucket=bucket_name,\n                    ServerSideEncryptionConfiguration={\n                        'Rules': [\n                            {\n                                'ApplyServerSideEncryptionByDefault': {\n                                    'SSEAlgorithm': 'aws:kms',\n                                    'KMSMasterKeyID': kms_key_arn.split('key/')[1]\n                                }\n                            }\n                        ]\n                    }\n                )\n            except Exception as e:\n                exit('Error encrypting bucket ' + bucket_name + ': ' + str(e))\n        \n        def put_access_block(s3, bucket_name):\n            try:\n                s3.put_public_access_block(\n                    Bucket=bucket_name,\n                    PublicAccessBlockConfiguration={\n                        'BlockPublicAcls': True,\n                        'IgnorePublicAcls': True,\n                        'BlockPublicPolicy': True,\n                        'RestrictPublicBuckets': True\n                    }\n                )\n            except Exception as e:\n                exit('Error setting public access block for bucket ' + bucket_name + ': ' + str(e))\n        \n        def put_bucket_acl(s3, bucket_name):\n            try:\n                s3.put_bucket_acl(\n                    Bucket=bucket_name,\n                    GrantReadACP='uri=http://acs.amazonaws.com/groups/s3/LogDelivery',\n                    GrantWrite='uri=http://acs.amazonaws.com/groups/s3/LogDelivery'\n                )\n            except Exception as e:\n                exit('Error setting ACL for bucket ' + bucket_name + ': ' + str(e))\n        \n        \n        \n\n    isEnd: false\n\n  - \n    name: CreateCloudTrailBucket\n    action: 'aws:executeScript'\n    outputs:\n      - Name: CloudTrailBucketName\n        Selector: $.Payload.cloudtrail_bucket\n        Type: String\n    inputs:\n      InputPayload: \n        account: '{{global:ACCOUNT_ID}}'\n        region: '{{global:REGION}}'\n        kms_key_arn: '{{KMSKeyArn}}'\n        logging_bucket: '{{CreateLoggingBucket.LoggingBucketName}}'\n      Runtime: python3.8\n      Handler: create_encrypted_bucket\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0                                     #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        def connect_to_s3(boto_config):\n            return boto3.client('s3', config=boto_config)\n        \n        def create_encrypted_bucket(event, context):\n        \n            boto_config = Config(\n                retries ={\n                  'mode': 'standard'\n                }\n            )\n            s3 = connect_to_s3(boto_config)\n        \n            kms_key_arn = event['kms_key_arn']\n            aws_account = event['account']\n            aws_region = event['region']\n            logging_bucket = event['logging_bucket']\n            bucket_name = 'so0111-aws-cloudtrail-' + aws_account\n        \n            if create_s3_bucket(s3, bucket_name, aws_region) == 'bucket_exists':\n                return {\"cloudtrail_bucket\": bucket_name}\n            put_bucket_encryption(s3, bucket_name, kms_key_arn)\n            put_public_access_block(s3, bucket_name)\n            put_bucket_logging(s3, bucket_name, logging_bucket)\n        \n            return {\"cloudtrail_bucket\": bucket_name}\n        \n        def create_s3_bucket(s3, bucket_name, aws_region):\n            try:\n                kwargs = {\n                    'Bucket': bucket_name,\n                    'ACL': 'private'\n                }\n                if aws_region != 'us-east-1':\n                    kwargs['CreateBucketConfiguration'] = {\n                        'LocationConstraint': aws_region\n                    }\n        \n                s3.create_bucket(**kwargs)\n        \n            except ClientError as client_ex:\n                exception_type = client_ex.response['Error']['Code']\n                if exception_type in [\"BucketAlreadyExists\", \"BucketAlreadyOwnedByYou\"]:\n                  print('Bucket ' + bucket_name + ' already exists')\n                  return 'bucket_exists'\n                else:\n                    exit('Error creating bucket ' + bucket_name + ' ' + str(client_ex))\n            except Exception as e:\n                exit('Error creating bucket ' + bucket_name + ' ' + str(e))\n        \n        def put_bucket_encryption(s3, bucket_name, kms_key_arn):\n            try:\n                s3.put_bucket_encryption(\n                    Bucket=bucket_name,\n                    ServerSideEncryptionConfiguration={\n                        'Rules': [\n                            {\n                                'ApplyServerSideEncryptionByDefault': {\n                                    'SSEAlgorithm': 'aws:kms',\n                                    'KMSMasterKeyID': kms_key_arn.split('key/')[1]\n                                }\n                            }\n                        ]\n                    }\n                )\n            except Exception as e:\n                print(e)\n                exit('Error applying encryption to bucket ' + bucket_name + ' with key ' + kms_key_arn)\n        \n        def put_public_access_block(s3, bucket_name):\n            try:\n                s3.put_public_access_block(\n                    Bucket=bucket_name,\n                    PublicAccessBlockConfiguration={\n                        'BlockPublicAcls': True,\n                        'IgnorePublicAcls': True,\n                        'BlockPublicPolicy': True,\n                        'RestrictPublicBuckets': True\n                    }\n                )\n            except Exception as e:\n                exit(f'Error setting public access block for bucket {bucket_name}: {str(e)}')\n        \n        def put_bucket_logging(s3, bucket_name, logging_bucket):\n            try:\n                s3.put_bucket_logging(\n                    Bucket=bucket_name,\n                    BucketLoggingStatus={\n                        'LoggingEnabled': {\n                            'TargetBucket': logging_bucket,\n                            'TargetPrefix': 'cloudtrail-access-logs'\n                        }\n                    }\n                )\n            except Exception as e:\n                print(e)\n                exit('Error setting public access block for bucket ' + bucket_name)\n        \n        \n    isEnd: false\n\n  - \n    name: CreateCloudTrailBucketPolicy\n    action: 'aws:executeScript'\n    inputs:\n      InputPayload: \n        cloudtrail_bucket: '{{CreateCloudTrailBucket.CloudTrailBucketName}}'\n        partition: '{{AWSPartition}}'\n        account: '{{global:ACCOUNT_ID}}'\n      Runtime: python3.8\n      Handler: create_bucket_policy\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import json\n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        def connect_to_s3(boto_config):\n            return boto3.client('s3', config=boto_config)\n        \n        def create_bucket_policy(event, context):\n        \n            boto_config = Config(\n                retries ={\n                  'mode': 'standard'\n                }\n            )\n            s3 = connect_to_s3(boto_config)\n        \n            cloudtrail_bucket = event['cloudtrail_bucket']\n            aws_partition = event['partition']\n            aws_account = event['account']\n            try:\n                bucket_policy = {\n                    \"Version\": \"2012-10-17\",\n                    \"Statement\": [\n                        {\n                            \"Sid\": \"AWSCloudTrailAclCheck20150319\",\n                            \"Effect\": \"Allow\",\n                            \"Principal\": {\n                                \"Service\": [\n                                    \"cloudtrail.amazonaws.com\"\n                                ]\n                            },\n                            \"Action\": \"s3:GetBucketAcl\",\n                            \"Resource\": \"arn:\" + aws_partition + \":s3:::\" + cloudtrail_bucket\n                        },\n                        {\n                            \"Sid\": \"AWSCloudTrailWrite20150319\",\n                            \"Effect\": \"Allow\",\n                            \"Principal\": {\n                                \"Service\": [\n                                    \"cloudtrail.amazonaws.com\"\n                                ]\n                            },\n                            \"Action\": \"s3:PutObject\",\n                            \"Resource\": \"arn:\" + aws_partition + \":s3:::\" + cloudtrail_bucket + \"/AWSLogs/\" + aws_account + \"/*\",\n                            \"Condition\": { \n                                \"StringEquals\": { \n                                    \"s3:x-amz-acl\": \"bucket-owner-full-control\"\n                                }\n                            }\n                        }\n                    ]\n                }\n                s3.put_bucket_policy(\n                    Bucket=cloudtrail_bucket,\n                    Policy=json.dumps(bucket_policy)\n                )\n                return {\n                    \"output\": {\n                        \"Message\": f'Set bucket policy for bucket {cloudtrail_bucket}'\n                    }\n                }\n            except Exception as e:\n                print(e)\n                exit('PutBucketPolicy failed: ' + str(e))\n        \n    isEnd: false\n\n  -\n    name: EnableCloudTrail\n    action: 'aws:executeScript'\n    outputs:\n      - Name: CloudTrailBucketName\n        Selector: $.Payload.cloudtrail_bucket\n        Type: String\n    inputs:\n      InputPayload: \n        cloudtrail_bucket: '{{CreateCloudTrailBucket.CloudTrailBucketName}}'\n        kms_key_arn: '{{KMSKeyArn}}'\n      Runtime: python3.8\n      Handler: enable_cloudtrail\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        def connect_to_cloudtrail(boto_config):\n            return boto3.client('cloudtrail', config=boto_config)\n        \n        def enable_cloudtrail(event, context):\n        \n            boto_config = Config(\n                retries ={\n                  'mode': 'standard'\n                }\n            )\n            ct = connect_to_cloudtrail(boto_config)\n        \n            try:\n                ct.create_trail(\n                    Name='multi-region-cloud-trail',\n                    S3BucketName=event['cloudtrail_bucket'],\n                    IncludeGlobalServiceEvents=True,\n                    EnableLogFileValidation=True,\n                    IsMultiRegionTrail=True,\n                    KmsKeyId=event['kms_key_arn']\n                )\n                ct.start_logging(\n                    Name='multi-region-cloud-trail'\n                )\n                return {\n                    \"output\": {\n                        \"Message\": f'CloudTrail Trail multi-region-cloud-trail created'\n                    }\n                }\n            except Exception as e:\n                exit('Error enabling AWS Config: ' + str(e))\n                \n\n    isEnd: false\n\n  -\n    name: Remediation\n    action: 'aws:executeScript'\n    outputs:\n      - Name: Output\n        Selector: $\n        Type: StringMap\n    inputs:\n      InputPayload:\n        cloudtrail_bucket: '{{CreateCloudTrailBucket.CloudTrailBucketName}}'\n        logging_bucket: '{{CreateLoggingBucket.LoggingBucketName}}'\n      Runtime: python3.8\n      Handler: process_results\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        def process_results(event, context):\n          print(f'Created encrypted CloudTrail bucket {event[\"cloudtrail_bucket\"]}')\n          print(f'Created access logging for CloudTrail bucket in bucket {event[\"logging_bucket\"]}')\n          print('Enabled multi-region AWS CloudTrail')\n          return {\n            \"response\": {\n              \"message\": \"AWS CloudTrail successfully enabled\",\n              \"status\": \"Success\"\n            }\n          }\n    isEnd: true\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR CreateCloudTrailMultiRegionTrail/Default"
   }
  },
  "SHARRCreateLogMetricFilterAndAlarm": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-CreateLogMetricFilterAndAlarm",
    "Content": "description: |\n  ### Document Name - SHARR-CreateLogMetricFilterAndAlarm\n  ## What does this document do?\n  Creates a metric filter for a given log group and also creates and alarm for the metric.\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * CloudWatch Log Group Name: Name of the CloudWatch log group to use to create metric filter\n  * Alarm Value: Threshhold value for the creating an alarm for the CloudWatch Alarm\n\n  ## Security Standards / Controls\n  * CIS v1.2.0:     3.1-3.14\nschemaVersion: '0.3'\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  LogGroupName:\n    type: String\n    description: Name of the log group to be used to create metric filter\n    allowedPattern: '.*'\n  FilterName:\n    type: String\n    description: Name for the metric filter\n    allowedPattern: '.*'\n  FilterPattern:\n    type: String\n    description: Filter pattern to create metric filter\n    allowedPattern: '.*'\n  MetricName:\n    type: String\n    description: Name of the metric for metric filter\n    allowedPattern: '.*'\n  MetricValue:\n    type: Integer\n    description: Value of the metric for metric filter\n  MetricNamespace:\n    type: String\n    description: Namespace where the metrics will be sent\n    allowedPattern: '.*'\n  AlarmName:\n    type: String\n    description: Name of the Alarm to be created for the metric filter\n    allowedPattern: '.*'\n  AlarmDesc:\n    type: String\n    description: Description of the Alarm to be created for the metric filter\n    allowedPattern: '.*'\n  AlarmThreshold:\n    type: Integer\n    description: Threshold value for the alarm\n  KMSKeyArn:\n    type: String\n    description: The ARN of a KMS key to use for encryption of the SNS Topic and Config bucket\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):kms:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\d):\\d{12}:(?:(?:alias/[A-Za-z0-9/-_])|(?:key/(?i:[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12})))$'\n  SNSTopicName:\n    type: String\n    allowedPattern: ^[a-zA-Z0-9][a-zA-Z0-9-_]{0,255}$\n\nmainSteps:\n  -\n    name: CreateTopic\n    action: 'aws:executeScript'\n    outputs:\n      - Name: TopicArn\n        Selector: $.Payload.topic_arn\n        Type: String\n    inputs:\n      InputPayload:\n        kms_key_arn: '{{KMSKeyArn}}'\n        topic_name: '{{SNSTopicName}}'\n      Runtime: python3.8\n      Handler: create_encrypted_topic\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0                             #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    # \n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import json\n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        boto_config = Config(\n            retries ={\n                'mode': 'standard'\n            }\n        )\n        \n        def connect_to_sns():\n            return boto3.client('sns', config=boto_config)\n        \n        def connect_to_ssm():\n            return boto3.client('ssm', config=boto_config)\n        \n        def create_encrypted_topic(event, context):\n        \n            kms_key_arn = event['kms_key_arn']\n            new_topic = False\n            topic_arn = ''\n            topic_name = event['topic_name']\n        \n            try:\n                sns = connect_to_sns()\n                topic_arn = sns.create_topic(\n                    Name=topic_name,\n                    Attributes={\n                        'KmsMasterKeyId': kms_key_arn.split('key/')[1]\n                    }\n                )['TopicArn']\n                new_topic = True\n        \n            except ClientError as client_exception:\n                exception_type = client_exception.response['Error']['Code']\n                if exception_type == 'InvalidParameter':\n                    print(f'Topic {topic_name} already exists. This remediation may have been run before.')\n                    print('Ignoring exception - remediation continues.')\n                    topic_arn = sns.create_topic(\n                        Name=topic_name\n                    )['TopicArn']\n                else:\n                    exit(f'ERROR: Unhandled client exception: {client_exception}')\n              \n            except Exception as e:\n                exit(f'ERROR: could not create SNS Topic {topic_name}: {str(e)}')\n        \n            if new_topic:\n                try:\n                    ssm = connect_to_ssm()\n                    ssm.put_parameter(\n                        Name='/Solutions/SO0111/SNS_Topic_CIS3.x',\n                        Description='SNS Topic for AWS Config updates',\n                        Type='String',\n                        Overwrite=True,\n                        Value=topic_arn\n                    )               \n                except Exception as e:\n                    exit(f'ERROR: could not create SNS Topic {topic_name}: {str(e)}')\n        \n            create_topic_policy(topic_arn)\n            \n            return {\"topic_arn\": topic_arn} \n        \n        def create_topic_policy(topic_arn):\n            sns = connect_to_sns()\n            try:\n                topic_policy = {\n                    \"Id\": \"Policy_ID\",\n                    \"Statement\": [\n                    {\n                        \"Sid\": \"AWSConfigSNSPolicy\",\n                        \"Effect\": \"Allow\",\n                        \"Principal\": {\n                        \"Service\": \"cloudwatch.amazonaws.com\"\n                        },\n                        \"Action\": \"SNS:Publish\",\n                        \"Resource\": topic_arn,\n                    }]\n                }\n                    \n                sns.set_topic_attributes(\n                    TopicArn=topic_arn,\n                    AttributeName='Policy',\n                    AttributeValue=json.dumps(topic_policy)\n                )\n            except Exception as e:\n                exit(f'ERROR: Failed to SetTopicAttributes for {topic_arn}: {str(e)}')\n        \n\n  -\n    name: CreateMetricFilerAndAlarm\n    action: 'aws:executeScript'\n    outputs:\n      - Name: Output\n        Selector: $.Payload.response\n        Type: StringMap\n    inputs:\n      InputPayload:\n        LogGroupName: '{{LogGroupName}}'\n        FilterName: '{{FilterName}}'\n        FilterPattern: '{{FilterPattern}}'\n        MetricName: '{{MetricName}}'\n        MetricNamespace: '{{MetricNamespace}}'\n        MetricValue: '{{MetricValue}}'\n        AlarmName: '{{AlarmName}}'\n        AlarmDesc: '{{AlarmDesc}}'\n        AlarmThreshold: '{{AlarmThreshold}}'\n        TopicArn: '{{CreateTopic.TopicArn}}'\n      Runtime: python3.8\n      Handler: verify\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                            #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import boto3\n        import logging\n        import os\n        from botocore.config import Config\n        \n        boto_config = Config(\n            retries={\n                'max_attempts': 10,\n                'mode': 'standard'\n            }\n        )\n        \n        log = logging.getLogger()\n        LOG_LEVEL = str(os.getenv('LogLevel', 'INFO'))\n        log.setLevel(LOG_LEVEL)\n        \n        \n        def get_service_client(service_name):\n            \"\"\"\n            Returns the service client for given the service name\n            :param service_name: name of the service\n            :return: service client\n            \"\"\"\n            log.debug(\"Getting the service client for service: {}\".format(service_name))\n            return boto3.client(service_name, config=boto_config)\n        \n        \n        def put_metric_filter(cw_log_group, filter_name, filter_pattern, metric_name, metric_namespace, metric_value):\n            \"\"\"\n            Puts the metric filter on the CloudWatch log group with provided values\n            :param cw_log_group: Name of the CloudWatch log group\n            :param filter_name: Name of the filter\n            :param filter_pattern: Pattern for the filter\n            :param metric_name: Name of the metric\n            :param metric_namespace: Namespace where metric is logged\n            :param metric_value: Value to be logged for the metric\n            \"\"\"\n            logs_client = get_service_client('logs')\n            log.debug(\"Putting the metric filter with values: {}\".format([\n                cw_log_group, filter_name, filter_pattern, metric_name, metric_namespace, metric_value]))\n            try:\n                logs_client.put_metric_filter(\n                    logGroupName=cw_log_group,\n                    filterName=filter_name,\n                    filterPattern=filter_pattern,\n                    metricTransformations=[\n                        {\n                            'metricName': metric_name,\n                            'metricNamespace': metric_namespace,\n                            'metricValue': str(metric_value),\n                            'unit': 'Count'\n                        }\n                    ]\n                )\n            except Exception as e:\n                exit(\"Exception occurred while putting metric filter: \" + str(e))\n            log.debug(\"Successfully added the metric filter.\")\n        \n        \n        def put_metric_alarm(alarm_name, alarm_desc, alarm_threshold, metric_name, metric_namespace, topic_arn):\n            \"\"\"\n            Puts the metric alarm for the metric name with provided values\n            :param alarm_name: Name for the alarm\n            :param alarm_desc: Description for the alarm\n            :param alarm_threshold: Threshold value for the alarm\n            :param metric_name: Name of the metric\n            :param metric_namespace: Namespace where metric is logged\n            \"\"\"\n            cw_client = get_service_client('cloudwatch')\n            log.debug(\"Putting the metric alarm with values {}\".format(\n                [alarm_name, alarm_desc, alarm_threshold, metric_name, metric_namespace]))\n            try:\n                cw_client.put_metric_alarm(\n                    AlarmName=alarm_name,\n                    AlarmDescription=alarm_desc,\n                    ActionsEnabled=True,\n                    OKActions=[\n                        topic_arn\n                    ],\n                    AlarmActions=[\n                        topic_arn\n                    ],\n                    MetricName=metric_name,\n                    Namespace=metric_namespace,\n                    Statistic='Sum',\n                    Period=300,\n                    Unit='Count',\n                    EvaluationPeriods=12,\n                    DatapointsToAlarm=1,\n                    Threshold=alarm_threshold,\n                    ComparisonOperator='GreaterThanOrEqualToThreshold',\n                    TreatMissingData='notBreaching'\n                )\n            except Exception as e:\n                exit(\"Exception occurred while putting metric alarm: \" + str(e))\n            log.debug(\"Successfully added metric alarm.\")\n        \n        \n        def verify(event, context):\n            log.info(\"Begin handler\")\n            log.debug(\"====Print Event====\")\n            log.debug(event)\n        \n            filter_name = event['FilterName']\n            filter_pattern = event['FilterPattern']\n            metric_name = event['MetricName']\n            metric_namespace = event['MetricNamespace']\n            metric_value = event['MetricValue']\n            alarm_name = event['AlarmName']\n            alarm_desc = event['AlarmDesc']\n            alarm_threshold = event['AlarmThreshold']\n            cw_log_group = event['LogGroupName']\n            topic_arn = event['TopicArn']\n        \n            put_metric_filter(cw_log_group, filter_name, filter_pattern, metric_name, metric_namespace, metric_value)\n            put_metric_alarm(alarm_name, alarm_desc, alarm_threshold, metric_name, metric_namespace, topic_arn)\n            return {\n                \"response\": {\n                    \"message\": f'Created filter {event[\"FilterName\"]} for metric {event[\"MetricName\"]}, and alarm {event[\"AlarmName\"]}',\n                    \"status\": \"Success\"\n                }\n            }\n        \n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR CreateLogMetricFilterAndAlarm/Default"
   }
  },
  "SHARREnableAutoScalingGroupELBHealthCheck": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableAutoScalingGroupELBHealthCheck",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n  ### Document name - SHARR-EnableAutoScalingGroupELBHealthCheck\n\n  ## What does this document do?\n  This runbook enables health checks for the Amazon EC2 Auto Scaling (Auto Scaling) group you specify using the [UpdateAutoScalingGroup](https://docs.aws.amazon.com/autoscaling/ec2/APIReference/API_UpdateAutoScalingGroup.html) API.\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.\n  * AutoScalingGroupARN: (Required) The Amazon Resource Name (ARN) of the auto scaling group that you want to enable health checks on.\n  * HealthCheckGracePeriod: (Optional) The amount of time, in seconds, that Auto Scaling waits before checking the health status of an Amazon Elastic Compute Cloud (Amazon EC2) instance that has come into service.\n\n  ## Output Parameters\n\n  * Remediation.Output - stdout messages from the remediation\n\n  ## Security Standards / Controls\n  * AFSBP v1.0.0: Autoscaling.1\n  * CIS v1.2.0:   2.1\n  * PCI:          Autoscaling.1\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  AutoScalingGroupName:\n    type: String\n    description: (Required) The Amazon Resource Name (ARN) of the auto scaling group that you want to enable health checks on.\n    allowedPattern: ^[\\u0020-\\uD7FF\\uE000-\\uFFFD\\uD800\\uDC00-\\uDBFF\\uDFFF]{1,255}$\n  HealthCheckGracePeriod:\n    type: Integer\n    description: (Optional) The amount of time, in seconds, that Auto Scaling waits before checking the health status of an Amazon Elastic Compute Cloud (Amazon EC2) instance that has come into service.\n    allowedPattern: ^[0-9]\\d*$\n    default: 300\n\noutputs:\n  -  Remediation.Output\nmainSteps:\n  - name: EnableELBHealthCheck\n    action: 'aws:executeAwsApi'\n    inputs:\n      Service: autoscaling\n      Api: UpdateAutoScalingGroup\n      AutoScalingGroupName: '{{AutoScalingGroupName}}'\n      HealthCheckType: ELB\n      HealthCheckGracePeriod: '{{HealthCheckGracePeriod}}'\n    description: Enable ELB health check type on ASG\n    outputs:\n      - Name: Output\n        Selector: $\n        Type: StringMap\n\n  - name: Remediation\n    action: 'aws:executeScript'\n    outputs:\n      - Name: Output\n        Selector: $.Payload.response\n        Type: StringMap\n    inputs:\n      InputPayload:\n        AsgName: '{{AutoScalingGroupName}}'\n      Runtime: python3.8\n      Handler: verify\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import json\n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        def connect_to_autoscaling(boto_config):\n            return boto3.client('autoscaling', config=boto_config)\n        \n        def verify(event, context):\n        \n            boto_config = Config(\n                retries ={\n                  'mode': 'standard'\n                }\n            )\n            asg_client = connect_to_autoscaling(boto_config)\n            asg_name = event['AsgName']\n            try:\n                desc_asg = asg_client.describe_auto_scaling_groups(\n                    AutoScalingGroupNames=[asg_name]\n                )\n                if len(desc_asg['AutoScalingGroups']) < 1:\n                    exit(f'No AutoScaling Group found matching {asg_name}')\n                    \n                health_check = desc_asg['AutoScalingGroups'][0]['HealthCheckType']\n                print(json.dumps(desc_asg['AutoScalingGroups'][0], default=str))\n                if (health_check == 'ELB'):\n                    return {\n                        \"response\": {\n                            \"message\": \"Autoscaling Group health check type updated to ELB\",\n                            \"status\": \"Success\"\n                        }\n                    }\n                else:\n                    return {\n                        \"response\": {\n                            \"message\": \"Autoscaling Group health check type is not ELB\",\n                            \"status\": \"Failed\"\n                        }\n                    }\n            except Exception as e:\n                exit(\"Exception while executing remediation: \" + str(e))\n        \n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableAutoScalingGroupELBHealthCheck/Default"
   }
  },
  "SHARREnableAWSConfig": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableAWSConfig",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n  ### Document name - SHARR-EnableAWSConfig\n\n  ## What does this document do?\n  Enables AWS Config:\n  * Turns on recording for all resources.\n  * Creates an encrypted bucket for Config logging.\n  * Creates a logging bucket for access logs for the config bucket\n  * Creates an SNS topic for Config notifications\n  * Creates a service-linked role\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.\n  * KMSKeyArn: KMS Customer-managed key to use for encryption of Config log data and SNS Topic\n  * AWSServiceRoleForConfig: (Optional) The name of the exiting IAM role to use for the Config service. Default: aws-service-role/config.amazonaws.com/AWSServiceRoleForConfig\n  * SNSTopicName: (Required) Name of the SNS Topic to use to post AWS Config messages.\n\n  ## Output Parameters\n  * Remediation.Output: STDOUT and messages from the remediation steps.\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  KMSKeyArn:\n    type: String\n    description: The ARN of a KMS key to use for encryption of the SNS Topic and Config bucket\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):kms:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\d):\\d{12}:(?:(?:alias/[A-Za-z0-9/-_])|(?:key/(?i:[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12})))$'\n  AWSServiceRoleForConfig:\n    type: String\n    default: aws-service-role/config.amazonaws.com/AWSServiceRoleForConfig\n    allowedPattern: '^(:?[\\w+=,.@-]+/)+[\\w+=,.@-]+$'\n  SNSTopicName:\n    type: String\n    allowedPattern: ^[a-zA-Z0-9][a-zA-Z0-9-_]{0,255}$\noutputs:\n  - Remediation.Output\n\nmainSteps:\n  -\n    name: CreateTopic\n    action: 'aws:executeScript'\n    outputs:\n      - Name: TopicArn\n        Selector: $.Payload.topic_arn\n        Type: String\n    inputs:\n      InputPayload:\n        kms_key_arn: '{{KMSKeyArn}}'\n        topic_name: '{{SNSTopicName}}'\n      Runtime: python3.8\n      Handler: create_encrypted_topic\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0                             #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    # \n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import json\n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        boto_config = Config(\n            retries ={\n                'mode': 'standard'\n            }\n        )\n        \n        def connect_to_sns():\n            return boto3.client('sns', config=boto_config)\n        \n        def connect_to_ssm():\n            return boto3.client('ssm', config=boto_config)\n        \n        def create_encrypted_topic(event, context):\n        \n            kms_key_arn = event['kms_key_arn']\n            new_topic = False\n            topic_arn = ''\n            topic_name = event['topic_name']\n        \n            try:\n                sns = connect_to_sns()\n                topic_arn = sns.create_topic(\n                    Name=topic_name,\n                    Attributes={\n                        'KmsMasterKeyId': kms_key_arn.split('key/')[1]\n                    }\n                )['TopicArn']\n                new_topic = True\n        \n            except ClientError as client_exception:\n                exception_type = client_exception.response['Error']['Code']\n                if exception_type == 'InvalidParameter':\n                    print(f'Topic {topic_name} already exists. This remediation may have been run before.')\n                    print('Ignoring exception - remediation continues.')\n                    topic_arn = sns.create_topic(\n                        Name=topic_name\n                    )['TopicArn']\n                else:\n                    exit(f'ERROR: Unhandled client exception: {client_exception}')\n              \n            except Exception as e:\n                exit(f'ERROR: could not create SNS Topic {topic_name}: {str(e)}')\n        \n            if new_topic:\n                try:\n                    ssm = connect_to_ssm()\n                    ssm.put_parameter(\n                        Name='/Solutions/SO0111/SNS_Topic_Config.1',\n                        Description='SNS Topic for AWS Config updates',\n                        Type='String',\n                        Overwrite=True,\n                        Value=topic_arn\n                    )               \n                except Exception as e:\n                    exit(f'ERROR: could not create SNS Topic {topic_name}: {str(e)}')\n        \n            create_topic_policy(topic_arn)\n            \n            return {\"topic_arn\": topic_arn} \n        \n        def create_topic_policy(topic_arn):\n            sns = connect_to_sns()\n            try:\n                topic_policy = {\n                    \"Id\": \"Policy_ID\",\n                    \"Statement\": [\n                    {\n                        \"Sid\": \"AWSConfigSNSPolicy\",\n                        \"Effect\": \"Allow\",\n                        \"Principal\": {\n                        \"Service\": \"config.amazonaws.com\"\n                        },\n                        \"Action\": \"SNS:Publish\",\n                        \"Resource\": topic_arn,\n                    }]\n                }\n                    \n                sns.set_topic_attributes(\n                    TopicArn=topic_arn,\n                    AttributeName='Policy',\n                    AttributeValue=json.dumps(topic_policy)\n                )\n            except Exception as e:\n                exit(f'ERROR: Failed to SetTopicAttributes for {topic_arn}: {str(e)}')\n        \n    isEnd: false\n\n  - name: CreateAccessLoggingBucket\n    action: 'aws:executeAutomation'\n    isEnd: false\n    inputs:\n      DocumentName: SHARR-CreateAccessLoggingBucket\n      RuntimeParameters:\n        BucketName: 'so0111-accesslogs-{{global:ACCOUNT_ID}}-{{global:REGION}}'\n        AutomationAssumeRole: 'arn:{{global:AWS_PARTITION}}:iam::{{global:ACCOUNT_ID}}:role/SO0111-CreateAccessLoggingBucket'\n\n  - name: CreateConfigBucket\n    action: 'aws:executeScript'\n    isEnd: false\n    outputs:\n      - Name: ConfigBucketName\n        Selector: $.Payload.config_bucket\n        Type: String\n    inputs:\n      InputPayload:\n        logging_bucket: 'so0111-accesslogs-{{global:ACCOUNT_ID}}-{{global:REGION}}'\n        account: '{{global:ACCOUNT_ID}}'\n        region: '{{global:REGION}}'\n        partition: '{{global:AWS_PARTITION}}'\n        kms_key_arn: '{{KMSKeyArn}}'\n      Runtime: python3.8\n      Handler: create_encrypted_bucket\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                            #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import json\n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        from botocore.retries import bucket\n        \n        boto_config = Config(\n            retries ={\n                'mode': 'standard'\n            }\n        )\n        \n        def connect_to_s3(boto_config):\n            return boto3.client('s3', config=boto_config)\n        \n        def create_bucket(bucket_name, aws_region):\n            s3 = connect_to_s3(boto_config)\n            try:\n                if aws_region == 'us-east-1':\n                    s3.create_bucket(\n                        ACL='private',\n                        Bucket=bucket_name\n                    )\n                else:\n                    s3.create_bucket(\n                        ACL='private',\n                        Bucket=bucket_name,\n                        CreateBucketConfiguration={\n                            'LocationConstraint': aws_region\n                        }\n                    )\n                return \"created\"\n        \n            except ClientError as ex:\n                exception_type = ex.response['Error']['Code']\n                # bucket already exists - return\n                if exception_type in [\"BucketAlreadyExists\", \"BucketAlreadyOwnedByYou\"]:\n                    print('Bucket ' + bucket_name + ' already exists')\n                    return \"already exists\"\n                else:\n                    exit(f'ERROR creating bucket {bucket_name}: {str(ex)}')\n            except Exception as e:\n                exit(f'ERROR creating bucket {bucket_name}: {str(e)}')\n        \n        def encrypt_bucket(bucket_name, kms_key):\n            s3 = connect_to_s3(boto_config)\n            try:\n                s3.put_bucket_encryption(\n                Bucket=bucket_name,\n                ServerSideEncryptionConfiguration={\n                'Rules': [\n                    {\n                    'ApplyServerSideEncryptionByDefault': {\n                        'SSEAlgorithm': 'aws:kms',\n                        'KMSMasterKeyID': kms_key\n                    }\n                    }\n                ]\n                }\n            )\n            except Exception as e:\n                exit(f'ERROR putting bucket encryption for {bucket_name}: {str(e)}')\n        \n        def block_public_access(bucket_name):\n            s3 = connect_to_s3(boto_config)\n            try:\n                s3.put_public_access_block(\n                    Bucket=bucket_name,\n                    PublicAccessBlockConfiguration={\n                        'BlockPublicAcls': True,\n                        'IgnorePublicAcls': True,\n                        'BlockPublicPolicy': True,\n                        'RestrictPublicBuckets': True\n                    }\n                )\n            except Exception as e:\n                exit(f'ERROR setting public access block for bucket {bucket_name}: {str(e)}')\n        \n        def enable_access_logging(bucket_name, logging_bucket):\n            s3 = connect_to_s3(boto_config)\n            try:\n                s3.put_bucket_logging(\n                    Bucket=bucket_name,\n                    BucketLoggingStatus={\n                    'LoggingEnabled': {\n                        'TargetBucket': logging_bucket,\n                        'TargetPrefix': f'access-logs/{bucket_name}'\n                    }\n                    }\n                )\n            except Exception as e:\n                exit(f'Error setting access logging for bucket {bucket_name}: {str(e)}')\n        \n        def create_bucket_policy(config_bucket, aws_partition):  \n            s3 = connect_to_s3(boto_config)   \n            try:\n                bucket_policy = {\n                    \"Version\": \"2012-10-17\",\n                    \"Statement\": [\n                    {\n                        \"Sid\": \"AWSConfigBucketPermissionsCheck\",\n                        \"Effect\": \"Allow\",\n                        \"Principal\": {\n                            \"Service\": [\n                                \"config.amazonaws.com\"\n                            ]\n                        },\n                        \"Action\": \"s3:GetBucketAcl\",\n                        \"Resource\": \"arn:\" + aws_partition + \":s3:::\" + config_bucket\n                    },\n                    {\n                        \"Sid\": \"AWSConfigBucketExistenceCheck\",\n                        \"Effect\": \"Allow\",\n                        \"Principal\": {\n                            \"Service\": [\n                                \"config.amazonaws.com\"\n                            ]\n                        },\n                        \"Action\": \"s3:ListBucket\",\n                        \"Resource\": \"arn:\" + aws_partition + \":s3:::\" + config_bucket\n                    },\n                    {\n                        \"Sid\": \"AWSConfigBucketDelivery\",\n                        \"Effect\": \"Allow\",\n                        \"Principal\": {\n                            \"Service\": [\n                                \"config.amazonaws.com\"    \n                            ]\n                        },\n                        \"Action\": \"s3:PutObject\",\n                        \"Resource\": \"arn:\" + aws_partition + \":s3:::\" + config_bucket + \"/*\",\n                        \"Condition\": { \n                            \"StringEquals\": { \n                                \"s3:x-amz-acl\": \"bucket-owner-full-control\"\n                            }\n                        }\n                    }\n                    ]\n                }\n                s3.put_bucket_policy(\n                    Bucket=config_bucket,\n                    Policy=json.dumps(bucket_policy)\n                )\n            except Exception as e:\n                exit(f'ERROR: PutBucketPolicy failed for {config_bucket}: {str(e)}')\n        \n        def create_encrypted_bucket(event, context):\n            \n            kms_key_arn = event['kms_key_arn']\n            aws_partition = event['partition']\n            aws_account = event['account']\n            aws_region = event['region']\n            logging_bucket = event['logging_bucket']\n            bucket_name = 'so0111-aws-config-' + aws_region + '-' + aws_account\n        \n            if create_bucket(bucket_name, aws_region) == 'already exists':\n                return {\"config_bucket\": bucket_name}\n        \n            encrypt_bucket(bucket_name, kms_key_arn.split('key/')[1])\n            block_public_access(bucket_name)\n            enable_access_logging(bucket_name, logging_bucket)\n            create_bucket_policy(bucket_name, aws_partition)\n        \n            return {\"config_bucket\": bucket_name}\n        \n\n  -\n    name: EnableConfig\n    action: 'aws:executeScript'\n    outputs:\n      - Name: ConfigBucketName\n        Selector: $.Payload.config_bucket\n        Type: String\n    inputs:\n      InputPayload:\n        partition: '{{global:AWS_PARTITION}}'\n        account: '{{global:ACCOUNT_ID}}'\n        region: '{{global:REGION}}'\n        config_bucket: '{{CreateConfigBucket.ConfigBucketName}}'\n        aws_service_role: '{{AWSServiceRoleForConfig}}'\n        topic_arn: '{{CreateTopic.TopicArn}}'\n      Runtime: python3.8\n      Handler: enable_config\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                            #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n         \n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        boto_config = Config(\n            retries ={\n                'mode': 'standard'\n            }\n        )\n        \n        def connect_to_config(boto_config):\n            return boto3.client('config', config=boto_config)\n        \n        def create_config_recorder(aws_partition, aws_account, aws_service_role):\n            cfgsvc = connect_to_config(boto_config)\n            try:\n                config_service_role_arn = 'arn:' + aws_partition + ':iam::' + aws_account + ':role/' + aws_service_role\n                cfgsvc.put_configuration_recorder(\n                    ConfigurationRecorder={\n                        'name': 'default',\n                        'roleARN': config_service_role_arn,\n                        'recordingGroup': {\n                            'allSupported': True,\n                            'includeGlobalResourceTypes': True\n                        }\n                    }\n                )\n            except ClientError as ex:\n                exception_type = ex.response['Error']['Code']\n                # recorder already exists - continue\n                if exception_type in [\"MaxNumberOfConfigurationRecordersExceededException\"]:\n                    print('Config Recorder already exists. Continuing.')\n                else:\n                    exit(f'ERROR: Boto3 ClientError enabling Config: {exception_type} - {str(ex)}')\n            except Exception as e:\n                exit(f'ERROR enabling AWS Config - create_config_recorder: {str(e)}')\n        \n        def create_delivery_channel(config_bucket, aws_account, topic_arn):\n            cfgsvc = connect_to_config(boto_config)\n            try:\n                cfgsvc.put_delivery_channel(\n                    DeliveryChannel={\n                        'name': 'default',\n                        's3BucketName': config_bucket,\n                        's3KeyPrefix': aws_account,\n                        'snsTopicARN': topic_arn,\n                        'configSnapshotDeliveryProperties': {\n                            'deliveryFrequency': 'Twelve_Hours'\n                        }\n                    }\n                )\n            except ClientError as ex:\n                exception_type = ex.response['Error']['Code']\n                # delivery channel already exists - return\n                if exception_type in [\"MaxNumberOfDeliveryChannelsExceededException\"]:\n                    print('DeliveryChannel already exists')\n                else:\n                    exit(f'ERROR: Boto3 ClientError enabling Config: {exception_type} - {str(ex)}')\n            except Exception as e:\n                exit(f'ERROR enabling AWS Config - create_delivery_channel: {str(e)}')\n        \n        def start_recorder():\n            cfgsvc = connect_to_config(boto_config)\n            try:\n                cfgsvc.start_configuration_recorder(\n                    ConfigurationRecorderName='default'\n                )\n            except Exception as e:\n                exit(f'ERROR enabling AWS Config: {str(e)}')          \n        \n        def enable_config(event, context):\n            aws_account = event['account']\n            aws_partition = event['partition']\n            aws_service_role = event['aws_service_role']\n            config_bucket = event['config_bucket']\n            topic_arn = event['topic_arn']\n        \n            create_config_recorder(aws_partition, aws_account, aws_service_role)\n            create_delivery_channel(config_bucket, aws_account, topic_arn)\n            start_recorder()\n        \n    isEnd: false\n\n  -\n    name: Remediation\n    action: 'aws:executeScript'\n    outputs:\n      - Name: Output\n        Selector: $\n        Type: StringMap\n    inputs:\n      InputPayload:\n        config_bucket: '{{CreateConfigBucket.ConfigBucketName}}'\n        logging_bucket: 'so0111-accesslogs-{{global:ACCOUNT_ID}}-{{global:REGION}}'\n        sns_topic_arn: '{{CreateTopic.TopicArn}}'\n      Runtime: python3.8\n      Handler: process_results\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                            #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n         \n        def process_results(event, context):\n            print(f'Created encrypted SNS topic {event[\"sns_topic_arn\"]}')\n            print(f'Created encrypted Config bucket {event[\"config_bucket\"]}')\n            print(f'Created access logging for Config bucket in bucket {event[\"logging_bucket\"]}')\n            print('Enabled AWS Config by creating a default recorder')\n            return {\n                \"response\": {\n                    \"message\": \"AWS Config successfully enabled\",\n                    \"status\": \"Success\"\n                }\n            }\n    isEnd: true\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableAWSConfig/Default"
   }
  },
  "SHARREnableCloudTrailToCloudWatchLogging": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableCloudTrailToCloudWatchLogging",
    "Content": "description: |\n  ### Document Name - SHARR-EnableCloudTrailToCloudWatchLogging\n  ## What does this document do?\n  Creates a CloudWatch logs group for CloudTrail data.\n  \n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * KMSKeyArn (from SSM): Arn of the KMS key to be used to encrypt data\n\n  ## Security Standards / Controls\n  * AFSBP v1.0.0:   N/A\n  * CIS v1.2.0:     2.4\n  * PCI:            CloudTrail.4\n\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  TrailName:\n    type: String\n    description: (Required) The name of the CloudTrail.\n    allowedPattern: '^[A-Za-z0-9._-]{3,128}$'\n  CloudWatchLogsRole:\n    type: String\n    description: (Required) The ARN of the role that allows CloudTrail to log to CloudWatch.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$' \n  LogGroupName:\n    type: String\n    description: (Required) The name of the Log Group for CloudTrail logs.\n    allowedPattern: '^[a-zA-Z0-9-_./]{1,512}$'\noutputs:\n  - UpdateTrailToCWLogs.Output\n\nmainSteps:\n  - \n    name: CreateLogGroup\n    action: 'aws:executeAwsApi'\n    inputs:\n      Service: logs\n      Api: CreateLogGroup\n      logGroupName: '{{LogGroupName}}'\n    description: Create the log group\n    outputs:\n      - Name: Output\n        Selector: $\n        Type: StringMap\n  - \n    name: WaitForCreation\n    action: 'aws:executeScript'\n    inputs:\n      InputPayload:       \n        LogGroup: '{{LogGroupName}}'\n      Runtime: python3.8\n      Handler: wait_for_loggroup\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import boto3\n        from botocore.config import Config\n        import time\n        \n        def connect_to_logs(boto_config):\n            return boto3.client('logs', config=boto_config)\n        \n        def wait_for_loggroup(event, context):\n            boto_config = Config(\n                retries ={\n                  'mode': 'standard'\n                }\n            )\n            cwl_client = connect_to_logs(boto_config)\n        \n            max_retries = 3\n            attempts = 0\n            while attempts < max_retries:\n                try:\n                    describe_group = cwl_client.describe_log_groups(logGroupNamePrefix=event['LogGroup'])\n                    print(len(describe_group['logGroups']))\n                    for group in describe_group['logGroups']:\n                        if group['logGroupName'] == event['LogGroup']:\n                            return str(group['arn'])\n                    # no match - wait and retry\n                    time.sleep(2)\n                    attempts += 1\n        \n                except Exception as e:\n                    exit(f'Failed to create Log Group {event[\"LogGroup\"]}: {str(e)}')\n        \n            exit(f'Failed to create Log Group {event[\"LogGroup\"]}: Timed out')\n        \n        \n    outputs:\n      - Name: CloudWatchLogsGroupArn\n        Selector: $.Payload\n        Type: String\n\n    isEnd: false\n\n  - \n    name: UpdateTrailToCWLogs\n    action: 'aws:executeAwsApi'\n    inputs:\n      Service: cloudtrail\n      Api: UpdateTrail\n      Name: '{{TrailName}}'\n      CloudWatchLogsLogGroupArn: '{{WaitForCreation.CloudWatchLogsGroupArn}}'\n      CloudWatchLogsRoleArn: '{{CloudWatchLogsRole}}'\n    description: Enable logging to CloudWatch Logs\n    outputs:\n      - Name: Output\n        Selector: $\n        Type: StringMap\n  \n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableCloudTrailToCloudWatchLogging/Default"
   }
  },
  "SHARREnableCloudTrailEncryption": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableCloudTrailEncryption",
    "Content": "description: |\n  ### Document Name - SHARR-EnableCloudTrailEncryption\n  ## What does this document do?\n  Enables encryption on a CloudTrail using the provided KMS CMK\n  \n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * KMSKeyArn (from SSM): Arn of the KMS key to be used to encrypt data\n  * TrailRegion: region of the CloudTrail to encrypt\n  * TrailArn: ARN of the CloudTrail to encrypt\n\n  ## Security Standards / Controls\n  * AFSBP v1.0.0:   CloudTrail.2\n  * CIS v1.2.0:     2.7\n  * PCI:            CloudTrail.1\n\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  KMSKeyArn:\n    type: String\n    default: >-\n      {{ssm:/Solutions/SO0111/CMK_REMEDIATION_ARN}}\n    description: The ARN of the KMS key created by SHARR for this remediation\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):kms:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\d):\\d{12}:(?:(?:alias/[A-Za-z0-9/-_])|(?:key/(?i:[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12})))$'\n  TrailRegion:\n    type: String\n    description: 'Region the CloudTrail is in'\n    allowedPattern: '^[a-z]{2}(?:-gov)?-[a-z]+-\\d$'\n  TrailArn:\n    type: String\n    description: 'ARN of the CloudTrail'\n    allowedPattern: '^arn:(?:aws|aws-cn|aws-us-gov):cloudtrail:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\d):\\d{12}:trail/[A-Za-z0-9._-]{3,128}$'\noutputs:\n  - Remediation.Output\n\nmainSteps:\n  - \n    name: Remediation\n    action: 'aws:executeScript'\n    outputs:\n      - Name: Output\n        Selector: $.Payload.response\n        Type: StringMap\n    inputs:\n      InputPayload: \n        exec_region: '{{global:REGION}}'\n        trail_region: '{{TrailRegion}}'\n        trail: '{{TrailArn}}'\n        region: '{{global:REGION}}'\n        kms_key_arn: '{{KMSKeyArn}}'        \n      Runtime: python3.8\n      Handler: enable_trail_encryption\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        def connect_to_cloudtrail(region, boto_config):\n            return boto3.client('cloudtrail', region_name=region, config=boto_config)\n        \n        def enable_trail_encryption(event, context):\n            \"\"\"\n            remediates CloudTrail.2 by enabling SSE-KMS\n            On success returns a string map\n            On failure returns NoneType\n            \"\"\"\n            boto_config = Config(\n                retries ={\n                  'mode': 'standard'\n                }\n            )\n          \n            if event['trail_region'] != event['exec_region']:\n                exit('ERROR: cross-region remediation is not yet supported')\n        \n            ctrail_client = connect_to_cloudtrail(event['trail_region'], boto_config)\n            kms_key_arn = event['kms_key_arn'] \n        \n            try:\n                ctrail_client.update_trail(\n                    Name=event['trail'],\n                    KmsKeyId=kms_key_arn\n                )\n                return {\n                    \"response\": {\n                        \"message\": f'Enabled KMS CMK encryption on {event[\"trail\"]}',\n                        \"status\": \"Success\"\n                    }\n                }\n            except Exception as e:\n                exit(f'Error enabling SSE-KMS encryption: {str(e)}')\n        \n\n    isEnd: true\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableCloudTrailEncryption/Default"
   }
  },
  "SHARREnableDefaultEncryptionS3": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableDefaultEncryptionS3",
    "Content": "description: |\n  ### Document name - SHARR-EnableDefaultEncryptionS3\n\n  ## What does this document do?\n  This document configures default encryption for an Amazon S3 Bucket.\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.\n  * BucketName: (Required) Name of the bucket to modify.\n  * AccountId: (Required) Account to which the bucket belongs\n\n  ## Output Parameters\n\n  * Remediation.Output - stdout messages from the remediation\n\n  ## Security Standards / Controls\n  * AFSBP v1.0.0: S3.4\n  * CIS v1.2.0:   n/a\n  * PCI:          S3.4\n\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AccountId:\n    type: String\n    description: Account ID of the account for the finding\n    allowedPattern: ^[0-9]{12}$\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  BucketName:\n    type: String\n    description: Name of the bucket to have a policy added\n    allowedPattern: (?=^.{3,63}$)(?!^(\\d+\\.)+\\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\\-]*[a-z0-9])\\.)*([a-z0-9]|[a-z0-9][a-z0-9\\-]*[a-z0-9])$)\n  KmsKeyAlias:\n    type: String\n    description: (Required) KMS Customer-Managed Key (CMK) alias or the default value which is created in the SSM parameter at solution deployment (default-s3-encryption) is used to identify that the s3 bucket encryption value should be set to AES-256.\n    default: 'default-s3-encryption'\n    allowedPattern: '^$|^[a-zA-Z0-9/_-]{1,256}$'\n\nmainSteps:\n  - name: ChooseEncryptionMethod\n    action: aws:branch\n    inputs:\n      Choices:\n      - NextStep: EncryptWithAES\n        Variable: '{{KmsKeyAlias}}'\n        StringEquals: 'default-s3-encryption'\n      Default:\n        EncryptWithCMK\n\n  - name: EncryptWithAES\n    action: aws:executeAwsApi\n    inputs:\n      Service: s3\n      Api: PutBucketEncryption\n      Bucket: '{{BucketName}}'\n      ExpectedBucketOwner: '{{AccountId}}'\n      ServerSideEncryptionConfiguration:\n        Rules:\n        - ApplyServerSideEncryptionByDefault:\n            SSEAlgorithm: 'AES256'\n          BucketKeyEnabled: true\n    isEnd: true\n\n  - name: EncryptWithCMK\n    action: aws:executeAwsApi\n    inputs:\n      Service: s3\n      Api: PutBucketEncryption\n      Bucket: '{{BucketName}}'\n      ExpectedBucketOwner: '{{AccountId}}'\n      ServerSideEncryptionConfiguration:\n        Rules:\n        - ApplyServerSideEncryptionByDefault:\n            SSEAlgorithm: 'aws:kms'\n            KMSMasterKeyID: '{{KmsKeyAlias}}'\n          BucketKeyEnabled: true\n    isEnd: true\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableDefaultEncryptionS3/Default"
   }
  },
  "SHARREnableVPCFlowLogs": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableVPCFlowLogs",
    "Content": "description: |\n  ### Document Name - SHARR-EnableVPCFlowLogs\n  ## What does this document do?\n  Enables VPC Flow Logs for a given VPC\n  \n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * VPC: VPC Id of the VPC for which logs are to be enabled\n  * RemediationRole: role arn of the role to use for logging\n  * KMSKeyArn: Amazon Resource Name (ARN) of the KMS Customer-Managed Key to use to encrypt the log group\n\n  ## Security Standards / Controls\n  * AFSBP v1.0.0:   CloudTrail.2\n  * CIS v1.2.0:     2.7\n  * PCI:            CloudTrail.1\n\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  VPC:\n    type: String\n    allowedPattern: '^vpc-[0-9a-f]{8,17}'\n    description: The VPC ID of the VPC\n  RemediationRole:\n    type: String\n    description: The ARN of the role that will allow VPC Flow Logs to log to CloudWatch logs\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  KMSKeyArn:\n    type: String\n    default: >-\n      {{ssm:/Solutions/SO0111/CMK_REMEDIATION_ARN}}\n    description: The ARN of the KMS key created by SHARR for remediations requiring encryption\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):kms:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\d):\\d{12}:(?:(?:alias/[A-Za-z0-9/-_])|(?:key/(?i:[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12})))$'\n\noutputs:\n  - Remediation.Output\n\nmainSteps:\n  - \n    name: Remediation\n    action: 'aws:executeScript'\n    outputs:\n      - Name: Output\n        Selector: $.Payload.response\n        Type: StringMap\n    inputs:\n      InputPayload: \n        vpc: '{{VPC}}'\n        remediation_role: '{{RemediationRole}}'   \n        kms_key_arn: '{{KMSKeyArn}}'      \n      Runtime: python3.8\n      Handler: enable_flow_logs\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import boto3\n        import time\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        def connect_to_logs(boto_config):\n            return boto3.client('logs', config=boto_config)\n        \n        def connect_to_ec2(boto_config):\n            return boto3.client('ec2', config=boto_config)\n        \n        def log_group_exists(client, group):\n            try:\n                log_group_verification = client.describe_log_groups(\n                    logGroupNamePrefix=group\n                )['logGroups']\n                if len(log_group_verification) >= 1:\n                    for existing_loggroup in log_group_verification:\n                        if existing_loggroup['logGroupName'] == group:\n                            return 1\n                return 0\n        \n            except Exception as e:\n                exit(f'EnableVPCFlowLogs failed - unhandled exception {str(e)}')\n        \n        def wait_for_loggroup(client, wait_interval, max_retries, loggroup):\n            attempts = 1\n            while not log_group_exists(client, loggroup):\n                time.sleep(wait_interval)\n                attempts += 1\n                if attempts > max_retries:\n                    exit(f'Timeout waiting for log group {loggroup} to become active')\n        \n        def flowlogs_active(client, loggroup):\n            # searches for flow log status, filtered on unique CW Log Group created earlier\n            try:\n                flow_status = client.describe_flow_logs(\n                    DryRun=False,\n                    Filters=[\n                        {\n                            'Name': 'log-group-name',\n                            'Values': [loggroup]\n                        },\n                    ]\n                )['FlowLogs']\n                if len(flow_status) == 1 and flow_status[0]['FlowLogStatus'] == 'ACTIVE':\n                    return 1\n                else:\n                    return 0\n        \n            except Exception as e:\n                exit(f'EnableVPCFlowLogs failed - unhandled exception {str(e)}')\n        \n        def wait_for_flowlogs(client, wait_interval, max_retries, loggroup):\n            attempts = 1\n            while not flowlogs_active(client, loggroup):\n                time.sleep(wait_interval)\n                attempts += 1\n                if attempts > max_retries:\n                    exit(f'Timeout waiting for flowlogs to log group {loggroup} to become active')\n        \n        def enable_flow_logs(event, context):\n            \"\"\"\n            remediates CloudTrail.2 by enabling SSE-KMS\n            On success returns a string map\n            On failure returns NoneType\n            \"\"\"\n            max_retries = event.get('retries', 12) # max number of waits for actions to complete.\n            wait_interval = event.get('wait', 5) # how many seconds between attempts\n        \n            boto_config_args = {\n                'retries': {\n                    'mode': 'standard'\n                }\n            }\n        \n            boto_config = Config(**boto_config_args)\n        \n            if 'vpc' not in event or 'remediation_role' not in event or 'kms_key_arn' not in event:\n                exit('Error: missing vpc from input')\n        \n            logs_client = connect_to_logs(boto_config)\n            ec2_client = connect_to_ec2(boto_config)\n            \n            kms_key_arn = event['kms_key_arn'] # for logs encryption at rest\n            \n            # set dynamic variable for CW Log Group for VPC Flow Logs\n            vpc_flow_loggroup = \"VPCFlowLogs/\" + event['vpc']        \n            # create cloudwatch log group\n            try:\n                logs_client.create_log_group(\n                    logGroupName=vpc_flow_loggroup,\n                    kmsKeyId=kms_key_arn\n                )\n            except ClientError as client_error:\n                exception_type = client_error.response['Error']['Code']\n        \n                if exception_type in [\"ResourceAlreadyExistsException\"]:\n                    print(f'CloudWatch Logs group {vpc_flow_loggroup} already exists')\n                else:\n                    exit(f'ERROR CREATING LOGGROUP {vpc_flow_loggroup}: {str(exception_type)}')\n                    \n            except Exception as e:\n                exit(f'ERROR CREATING LOGGROUP {vpc_flow_loggroup}: {str(e)}')\n        \n            # wait for CWL creation to propagate\n            wait_for_loggroup(logs_client, wait_interval, max_retries, vpc_flow_loggroup)\n        \n            # create VPC Flow Logging\n            try:\n                ec2_client.create_flow_logs(\n                    DryRun=False,\n                    DeliverLogsPermissionArn=event['remediation_role'],\n                    LogGroupName=vpc_flow_loggroup,\n                    ResourceIds=[event['vpc']],\n                    ResourceType='VPC',\n                    TrafficType='REJECT',\n                    LogDestinationType='cloud-watch-logs'\n                )\n            except ClientError as client_error:\n                exception_type = client_error.response['Error']['Code']\n        \n                if exception_type in [\"FlowLogAlreadyExists\"]:\n                    return {\n                        \"response\": {\n                            \"message\": f'VPC Flow Logs for {event[\"vpc\"]} already enabled',\n                            \"status\": \"Success\"\n                        }\n                    }\n                else:\n                    exit(f'ERROR CREATING LOGGROUP {vpc_flow_loggroup}: {str(exception_type)}')\n            except Exception as e:\n                exit(f'create_flow_logs failed {str(e)}')\n        \n            # wait for Flow Log creation to propagate. Exits on timeout (no need to check results)\n            wait_for_flowlogs(ec2_client, wait_interval, max_retries, vpc_flow_loggroup)\n        \n            # wait_for_flowlogs will exit if unsuccessful after max_retries * wait_interval (60 seconds by default)\n            return {\n                \"response\": {\n                    \"message\": f'VPC Flow Logs enabled for {event[\"vpc\"]} to {vpc_flow_loggroup}',\n                    \"status\": \"Success\"\n                }\n            }\n        \n\n    isEnd: true\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableVPCFlowLogs/Default"
   }
  },
  "SHARRCreateAccessLoggingBucket": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-CreateAccessLoggingBucket",
    "Content": "description: |\n  ### Document Name - SHARR-CreateAccessLoggingBucket\n  \n  ## What does this document do?\n  Creates an S3 bucket for access logging.\n  \n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * BucketName: (Required) Name of the bucket to create\n\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  BucketName:\n    type: String\n    description: (Required) The bucket name (not the ARN).\n    allowedPattern: (?=^.{3,63}$)(?!^(\\d+\\.)+\\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\\-]*[a-z0-9])\\.)*([a-z0-9]|[a-z0-9][a-z0-9\\-]*[a-z0-9])$)\noutputs:\n  - CreateAccessLoggingBucket.Output\n\nmainSteps:\n  - \n    name: CreateAccessLoggingBucket\n    action: 'aws:executeScript'\n    inputs:\n      InputPayload:       \n        BucketName: '{{BucketName}}'\n        AWS_REGION: '{{global:REGION}}'\n      Runtime: python3.8\n      Handler: create_logging_bucket\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.    #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                                        #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import boto3\n        from botocore.exceptions import ClientError\n        from botocore.config import Config\n        \n        def connect_to_s3(boto_config):\n            return boto3.client('s3', config=boto_config)\n        \n        def create_logging_bucket(event, context):\n            boto_config = Config(\n                retries ={\n                  'mode': 'standard'\n                }\n            )\n            s3 = connect_to_s3(boto_config)\n        \n            try:\n                kwargs = {\n                    'Bucket': event['BucketName'],\n                    'GrantWrite': 'uri=http://acs.amazonaws.com/groups/s3/LogDelivery',\n                    'GrantReadACP': 'uri=http://acs.amazonaws.com/groups/s3/LogDelivery'\n                }\n                if event['AWS_REGION'] != 'us-east-1':\n                    kwargs['CreateBucketConfiguration'] = {\n                        'LocationConstraint': event['AWS_REGION']\n                    }\n        \n                s3.create_bucket(**kwargs)\n        \n                s3.put_bucket_encryption(\n                    Bucket=event['BucketName'],\n                    ServerSideEncryptionConfiguration={\n                        'Rules': [\n                            {\n                                'ApplyServerSideEncryptionByDefault': {\n                                    'SSEAlgorithm': 'AES256'\n                                }\n                            }\n                        ]\n                    }\n                )\n                return {\n                    \"output\": {\n                        \"Message\": f'Bucket {event[\"BucketName\"]} created'\n                    }\n                }\n            except ClientError as error:\n                if error.response['Error']['Code'] != 'BucketAlreadyExists' and \\\n                    error.response['Error']['Code'] != 'BucketAlreadyOwnedByYou':\n                    exit(str(error))\n                else:\n                    return {\n                        \"output\": {\n                            \"Message\": f'Bucket {event[\"BucketName\"]} already exists'\n                        }\n                    }\n            except Exception as e:\n                print(e)\n                exit(str(e))\n        \n    outputs:\n      - Name: Output\n        Selector: $.Payload.output\n        Type: StringMap\n\n    isEnd: true\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR CreateAccessLoggingBucket/Default"
   }
  },
  "SHARRMakeEBSSnapshotsPrivate": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-MakeEBSSnapshotsPrivate",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n  ### Document name - SHARR-MakeEBSSnapshotPrivate\n\n  ## What does this document do?\n  This runbook works an the account level to remove public share on all EBS snapshots\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.\n\n  ## Output Parameters\n\n  * Remediation.Output - stdout messages from the remediation\n\n  ## Security Standards / Controls\n  * AFSBP v1.0.0: EC2.1\n  * CIS v1.2.0:   n/a\n  * PCI:          EC2.1\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AccountId:\n    type: String\n    description: Account ID of the account for which snapshots are to be checked.\n    allowedPattern: ^[0-9]{12}$\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  TestMode:\n    type: Boolean\n    description: Enables test mode, which generates a list of fake volume Ids\n    default: false\n\noutputs:\n  -  Remediation.Output\nmainSteps:\n  - name: GetPublicSnapshotIds\n    action: 'aws:executeScript'\n    outputs:\n      - Name: Snapshots\n        Selector: $.Payload\n        Type: StringList\n    inputs:\n      InputPayload:\n        region: '{{global:REGION}}'\n        account_id: '{{AccountId}}'\n        testmode: '{{TestMode}}'\n      Runtime: python3.8\n      Handler: get_public_snapshots\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                            #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import json\n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        boto_config = Config(\n            retries = {\n                    'mode': 'standard',\n                    'max_attempts': 10\n                }\n            )\n        \n        def connect_to_ec2(boto_config):\n            return boto3.client('ec2', config=boto_config)\n        \n        def get_public_snapshots(event, context):\n            account_id = event['account_id']\n        \n            if 'testmode' in event and event['testmode']:\n                return [\n                    \"snap-12341234123412345\",\n                    \"snap-12341234123412345\",\n                    \"snap-12341234123412345\",\n                    \"snap-12341234123412345\",\n                    \"snap-12341234123412345\"\n                ]\n        \n            return list_public_snapshots(account_id)\n        \n        def list_public_snapshots(account_id):\n            ec2 = connect_to_ec2(boto_config)\n            control_token = 'start'\n            try:\n        \n                public_snapshot_ids = []\n        \n                while control_token:\n        \n                    if control_token == 'start': # needed a value to start the loop. Now reset it\n                        control_token = ''\n        \n                    kwargs = {\n                        'MaxResults': 100, \n                        'OwnerIds': [ account_id ],\n                        'RestorableByUserIds': [ 'all' ]\n                    }\n                    if control_token:\n                        kwargs['NextToken'] = control_token\n                        \n                    response = ec2.describe_snapshots(\n                                **kwargs\n                        )\n                \n                    for snapshot in response['Snapshots']:\n                        public_snapshot_ids.append(snapshot['SnapshotId'])\n        \n                    if 'NextToken' in response:\n                        control_token = response['NextToken']\n                    else:\n                        control_token = ''\n        \n                return public_snapshot_ids\n                \n            except Exception as e:\n                print(e)\n                exit('Failed to describe_snapshots')\n        \n\n  - name: Remediation\n    action: 'aws:executeScript'\n    outputs:\n      - Name: Output\n        Selector: $.Payload.response\n        Type: StringMap\n    inputs:\n      InputPayload:\n        region: '{{global:REGION}}'\n        snapshots: '{{GetPublicSnapshotIds.Snapshots}}'\n      Runtime: python3.8\n      Handler: make_snapshots_private\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                            #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import json\n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        def connect_to_ec2(boto_config):\n            return boto3.client('ec2', config=boto_config)\n        \n        def make_snapshots_private(event, context):\n            boto_config = Config(\n                retries = {\n                        'mode': 'standard',\n                        'max_attempts': 10\n                    }\n                )\n            ec2 = connect_to_ec2(boto_config)\n        \n            remediated = []\n            snapshots = event['snapshots']\n        \n            success_count = 0\n            \n            for snapshot_id in snapshots:\n                try:\n                    ec2.modify_snapshot_attribute(\n                        Attribute='CreateVolumePermission',\n                        CreateVolumePermission={\n                            'Remove': [{'Group': 'all'}]\n                        },\n                        SnapshotId=snapshot_id\n                    )\n                    print(f'Snapshot {snapshot_id} permissions set to private')\n        \n                    remediated.append(snapshot_id)\n                    success_count += 1\n                except Exception as e:\n                    print(e)\n                    print(f'FAILED to remediate Snapshot {snapshot_id}')\n        \n            result=json.dumps(ec2.describe_snapshots(\n                    SnapshotIds=remediated\n                ), indent=2, default=str)\n            print(result)\n        \n            return {\n                \"response\": {\n                    \"message\": f'{success_count} of {len(snapshots)} Snapshot permissions set to private',\n                    \"status\": \"Success\"\n                }\n            }\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR MakeEBSSnapshotsPrivate/Default"
   }
  },
  "SHARRMakeRDSSnapshotPrivate": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-MakeRDSSnapshotPrivate",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n  ### Document name - SHARR-MakeRDSSnapshotPrivate\n\n  ## What does this document do?\n  This runbook removes public access to an RDS Snapshot\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.\n  * DBSnapshotId: identifier of the public snapshot\n  * DBSnapshotType: snapshot or cluster-snapshot\n\n  ## Output Parameters\n\n  * Remediation.Output - stdout messages from the remediation\n\n  ## Security Standards / Controls\n  * AFSBP v1.0.0: RDS.1\n  * CIS v1.2.0:   n/a\n  * PCI:          RDS.1\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  DBSnapshotId:\n    type: String\n    allowedPattern: ^[a-zA-Z](?:[0-9a-zA-Z]+[-]{1})*[0-9a-zA-Z]{1,}$\n  DBSnapshotType:\n    type: String\n    allowedValues:\n    - cluster-snapshot\n    - snapshot\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n\noutputs:\n  -  MakeRDSSnapshotPrivate.Output\nmainSteps:\n  - name: MakeRDSSnapshotPrivate\n    action: 'aws:executeScript'\n    outputs:\n      - Name: Output\n        Selector: $.Payload.response\n        Type: StringMap\n    inputs:\n      InputPayload:\n        DBSnapshotType: '{{DBSnapshotType}}'\n        DBSnapshotId: '{{DBSnapshotId}}'\n      Runtime: python3.8\n      Handler: make_snapshot_private\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                            #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import json\n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        def connect_to_rds():\n            boto_config = Config(\n                retries ={\n                    'mode': 'standard'\n                }\n            )\n            return boto3.client('rds', config=boto_config)\n        \n        def make_snapshot_private(event, context):\n        \n            rds_client = connect_to_rds()\n            snapshot_id = event['DBSnapshotId']\n            snapshot_type = event['DBSnapshotType']\n            try:\n                if (snapshot_type == 'snapshot'):\n                    rds_client.modify_db_snapshot_attribute(\n                        DBSnapshotIdentifier=snapshot_id,\n                        AttributeName='restore',\n                        ValuesToRemove=['all']\n                    )\n                elif (snapshot_type == 'cluster-snapshot'):\n                    rds_client.modify_db_cluster_snapshot_attribute(\n                        DBClusterSnapshotIdentifier=snapshot_id,\n                        AttributeName='restore',\n                        ValuesToRemove=['all']\n                    )\n                else:\n                    exit(f'Unrecognized snapshot_type {snapshot_type}')\n        \n                print(f'Remediation completed: {snapshot_id} public access removed.')\n                return {\n                    \"response\": {\n                        \"message\": f'Snapshot {snapshot_id} permissions set to private',\n                        \"status\": \"Success\"\n                    }\n                }\n            except Exception as e:\n                exit(f'Remediation failed for {snapshot_id}: {str(e)}')\n        \n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR MakeRDSSnapshotPrivate/Default"
   }
  },
  "SHARRRemoveLambdaPublicAccess": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-RemoveLambdaPublicAccess",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n  ### Document name - SHARR-RemoveLambdaPublicAccess\n\n  ## What does this document do?\n  This document removes the public resource policy. A public resource policy\n  contains a principal \"*\" or AWS: \"*\", which allows public access to the\n  function. The remediation is to remove the SID of the public policy.\n\n  ## Input Parameters\n  * FunctionName: name of the AWS Lambda function that has open access policies\n  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.\n\n  ## Output Parameters\n\n  * RemoveLambdaPublicAccess.Output - stdout messages from the remediation\n\n  ## Security Standards / Controls\n  * AFSBP v1.0.0: Lambda.1\n  * CIS v1.2.0:   n/a\n  * PCI:          Lambda.1\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  FunctionName:\n    type: String\n    allowedPattern: ^[a-zA-Z0-9\\-_]{1,64}$\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n\noutputs:\n  -  RemoveLambdaPublicAccess.Output\nmainSteps:\n  - name: RemoveLambdaPublicAccess\n    action: 'aws:executeScript'\n    outputs:\n      - Name: Output\n        Selector: $.Payload.response\n        Type: StringMap\n    inputs:\n      InputPayload:\n        FunctionName: '{{FunctionName}}'\n      Runtime: python3.8\n      Handler: remove_lambda_public_access\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                            #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import json\n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        boto_config = Config(\n            retries = {\n                'mode': 'standard',\n                'max_attempts': 10\n            }\n        )\n        \n        def connect_to_lambda(boto_config):\n            return boto3.client('lambda', config=boto_config)\n        \n        def print_policy_before(policy):\n            print('Resource Policy to be deleted:')\n            print(json.dumps(policy, indent=2, default=str))\n        \n        def remove_resource_policy(functionname, sid, client):\n            try:\n                client.remove_permission(\n                    FunctionName=functionname,\n                    StatementId=sid\n                )\n                print(f'SID {sid} removed from Lambda function {functionname}')\n            except Exception as e:\n                exit(f'FAILED: SID {sid} was NOT removed from Lambda function {functionname} - {str(e)}')\n        \n        def remove_public_statement(client, functionname, statement, principal_source):\n            for principal in list(principal_source):\n                if principal == \"*\" or (isinstance(principal, dict) and principal.get(\"AWS\",\"\") == \"*\"):\n                    print_policy_before(statement)\n                    remove_resource_policy(functionname, statement['Sid'], client)\n                    break # there will only be one that matches\n        \n        def remove_lambda_public_access(event, context):\n        \n            client = connect_to_lambda(boto_config)\n        \n            functionname = event['FunctionName']\n            try:\n                response = client.get_policy(FunctionName=functionname)\n                policy = response['Policy']\n                policy_json = json.loads(policy)\n                statements = policy_json['Statement']\n        \n                print('Scanning for public resource policies in ' + functionname)\n        \n                for statement in statements:\n                    remove_public_statement(client, functionname, statement, list(statement['Principal']))\n        \n                client.get_policy(FunctionName=functionname)\n        \n                verify(functionname)\n            except ClientError as ex:\n                exception_type = ex.response['Error']['Code']\n                if exception_type in ['ResourceNotFoundException']:\n                    print(\"Remediation completed. Resource policy is now empty.\")\n                else:\n                    exit(f'ERROR: Remediation failed for RemoveLambdaPublicAccess: {str(ex)}')\n            except Exception as e:\n                exit(f'ERROR: Remediation failed for RemoveLambdaPublicAccess: {str(e)}')\n        \n        def verify(function_name_to_check):\n        \n            client = connect_to_lambda(boto_config)\n        \n            try:\n                response = client.get_policy(FunctionName=function_name_to_check)\n        \n                print(\"Remediation executed successfully. Policy after:\")\n                print(json.dumps(response, indent=2, default=str))\n                \n            except ClientError as ex:\n                exception_type = ex.response['Error']['Code']\n                if exception_type in ['ResourceNotFoundException']:\n                    print(\"Remediation completed. Resource policy is now empty.\")\n                else:\n                    exit(f'ERROR: {exception_type} on get_policy')\n            except Exception as e:\n                exit(f'Exception while retrieving lambda function policy: {str(e)}')\n        \n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR RemoveLambdaPublicAccess/Default"
   }
  },
  "SHARRRevokeUnrotatedKeys": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-RevokeUnrotatedKeys",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n  ### Document Name - SHARR-RevokeUnrotatedKeys\n\n  ## What does this document do?\n  This document disables active keys that have not been rotated for more than 90 days. Note that this remediation is **DISRUPTIVE**. It will disabled keys that have been used within the previous 90 days by have not been rotated by using the [UpdateAccessKey API](https://docs.aws.amazon.com/IAM/latest/APIReference/API_UpdateAccessKey.html). Please note, this automation document requires AWS Config to be enabled.\n\n  ## Input Parameters\n  * Finding: (Required) Security Hub finding details JSON\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * MaxCredentialUsageAge: (Optional) Maximum number of days a key is allowed to be unrotated before revoking it. DEFAULT: 90\n\n  ## Output Parameters\n  * RevokeUnrotatedKeys.Output\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  IAMResourceId:\n    type: String\n    description: (Required) IAM resource unique identifier.\n    allowedPattern: ^[\\w+=,.@_-]{1,128}$\n  MaxCredentialUsageAge:\n    type: String\n    description: (Required) Maximum number of days within which a credential must be used. The default value is 90 days.\n    allowedPattern: ^[1-9][0-9]{0,3}|10000$\n    default: \"90\"\noutputs:\n  - RevokeUnrotatedKeys.Output\nmainSteps:\n  - name: RevokeUnrotatedKeys\n    action: aws:executeScript\n    timeoutSeconds: 600\n    isEnd: true\n    description: |\n      ## RevokeUnrotatedKeys\n\n      This step deactivates IAM user access keys that have not been rotated in more than MaxCredentialUsageAge days\n      ## Outputs\n      * Output: Success message or failure Exception.\n    inputs:\n      Runtime: python3.8\n      Handler: unrotated_key_handler\n      InputPayload:\n        IAMResourceId: \"{{ IAMResourceId }}\"\n        MaxCredentialUsageAge: \"{{ MaxCredentialUsageAge }}\"\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                            #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        from datetime import datetime, timezone, timedelta\n        import boto3\n        from botocore.config import Config\n        \n        boto_config = Config(\n            retries ={\n                'mode': 'standard'\n            }\n        )\n        \n        responses = {}\n        responses[\"DeactivateUnusedKeysResponse\"] = []\n        \n        def connect_to_iam(boto_config):\n            return boto3.client('iam', config=boto_config)\n        \n        def connect_to_config(boto_config):\n            return boto3.client('config', config=boto_config)\n        \n        def get_user_name(resource_id):\n            config_client = connect_to_config(boto_config)\n            list_discovered_resources_response = config_client.list_discovered_resources(\n                resourceType='AWS::IAM::User',\n                resourceIds=[resource_id]\n            )\n            resource_name = list_discovered_resources_response.get(\"resourceIdentifiers\")[0].get(\"resourceName\")\n            return resource_name\n        \n        def list_access_keys(user_name, include_inactive=False):\n            iam_client = connect_to_iam(boto_config)\n            active_keys = []\n            keys = iam_client.list_access_keys(UserName=user_name).get(\"AccessKeyMetadata\", [])\n            for key in keys:\n                if include_inactive or key.get('Status') == 'Active':\n                    active_keys.append(key)\n            return active_keys\n        \n        def deactivate_unused_keys(access_keys, max_credential_usage_age, user_name):\n            iam_client = connect_to_iam(boto_config)\n            for key in access_keys:\n                print(key)\n                last_used = iam_client.get_access_key_last_used(AccessKeyId=key.get(\"AccessKeyId\")).get(\"AccessKeyLastUsed\")\n                deactivate = False\n        \n                now = datetime.now(timezone.utc)\n                days_since_creation = (now - key.get(\"CreateDate\")).days\n                last_used_days = (now - last_used.get(\"LastUsedDate\", now)).days\n        \n                print(f'Key {key.get(\"AccessKeyId\")} is {days_since_creation} days old and last used {last_used_days} days ago')\n        \n                if days_since_creation > max_credential_usage_age:\n                    deactivate = True\n        \n                if last_used_days > max_credential_usage_age:\n                    deactivate = True\n        \n                if deactivate:\n                    deactivate_key(user_name, key.get(\"AccessKeyId\"))\n        \n        def deactivate_key(user_name, access_key):\n            iam_client = connect_to_iam(boto_config)\n            responses[\"DeactivateUnusedKeysResponse\"].append({\"AccessKeyId\": access_key, \"Response\": iam_client.update_access_key(UserName=user_name, AccessKeyId=access_key, Status=\"Inactive\")})\n        \n        def verify_expired_credentials_revoked(responses, user_name):\n            if responses.get(\"DeactivateUnusedKeysResponse\"):\n                for key in responses.get(\"DeactivateUnusedKeysResponse\"):\n                    key_data = next(filter(lambda x: x.get(\"AccessKeyId\") == key.get(\"AccessKeyId\"), list_access_keys(user_name, True)))\n                    if key_data.get(\"Status\") != \"Inactive\":\n                        error_message = \"VERIFICATION FAILED. ACCESS KEY {} NOT DEACTIVATED\".format(key_data.get(\"AccessKeyId\"))\n                        raise Exception(error_message)\n        \n            return {\n                \"output\": \"Verification of unrotated access keys is successful.\",\n                \"http_responses\": responses\n            }\n        \n        def unrotated_key_handler(event, context):\n            user_name = get_user_name(event.get(\"IAMResourceId\"))\n            max_credential_usage_age = int(event.get(\"MaxCredentialUsageAge\"))\n            access_keys = list_access_keys(user_name)\n            deactivate_unused_keys(access_keys, max_credential_usage_age, user_name)\n            return verify_expired_credentials_revoked(responses, user_name)\n        \n\n    outputs:\n      - Name: Output\n        Selector: $.Payload\n        Type: StringMap\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR RevokeUnrotatedKeys/Default"
   }
  },
  "SHARRSetSSLBucketPolicy": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-SetSSLBucketPolicy",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n  ### Document name - SHARR-SetSSLBucketPolicy\n\n  ## What does this document do?\n  This document adds a bucket policy to require transmission over HTTPS for the given S3 bucket by adding a policy statement to the bucket policy.\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.\n  * BucketName: (Required) Name of the bucket to modify.\n  * AccountId: (Required) Account to which the bucket belongs\n\n  ## Output Parameters\n\n  * Remediation.Output - stdout messages from the remediation\n\n  ## Security Standards / Controls\n  * AFSBP v1.0.0: S3.5\n  * CIS v1.2.0:   n/a\n  * PCI:          S3.5\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AccountId:\n    type: String\n    description: Account ID of the account for the finding\n    allowedPattern: ^[0-9]{12}$\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  BucketName:\n    type: String\n    description: Name of the bucket to have a policy added\n    allowedPattern: (?=^.{3,63}$)(?!^(\\d+\\.)+\\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\\-]*[a-z0-9])\\.)*([a-z0-9]|[a-z0-9][a-z0-9\\-]*[a-z0-9])$)\n\noutputs:\n  -  Remediation.Output\nmainSteps:\n  - name: Remediation\n    action: 'aws:executeScript'\n    outputs:\n      - Name: Output\n        Selector: $.Payload.response\n        Type: StringMap\n    inputs:\n      InputPayload:\n        accountid: '{{AccountId}}'\n        bucket: '{{BucketName}}'\n      Runtime: python3.8\n      Handler: add_ssl_bucket_policy\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                            #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        \n        import json\n        import boto3\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        boto_config = Config(\n            retries = {\n                    'mode': 'standard',\n                    'max_attempts': 10\n                }\n            )\n        \n        def connect_to_s3():\n            return boto3.client('s3', config=boto_config)\n        \n        def policy_to_add(bucket):\n            return {\n                \"Sid\": \"AllowSSLRequestsOnly\",\n                \"Action\": \"s3:*\",\n                \"Effect\": \"Deny\",\n                \"Resource\": [\n                    f'arn:aws:s3:::{bucket}',\n                    f'arn:aws:s3:::{bucket}/*'\n                ],\n                \"Condition\": {\n                    \"Bool\": {\n                            \"aws:SecureTransport\": \"false\"\n                    }\n                },\n                \"Principal\": \"*\"\n            }\n        def new_policy():\n            return {\n                \"Id\": \"BucketPolicy\",\n                \"Version\": \"2012-10-17\",\n                \"Statement\": []\n            }\n        \n        def add_ssl_bucket_policy(event, context):\n            bucket_name = event['bucket']\n            account_id = event['accountid']\n            s3 = connect_to_s3()\n            bucket_policy = {}\n            try:\n                existing_policy = s3.get_bucket_policy(\n                    Bucket=bucket_name,\n                    ExpectedBucketOwner=account_id\n                )\n                bucket_policy = json.loads(existing_policy['Policy'])\n            except ClientError as ex:\n                exception_type = ex.response['Error']['Code']\n                # delivery channel already exists - return\n                if exception_type not in [\"NoSuchBucketPolicy\"]:\n                    exit(f'ERROR: Boto3 s3 ClientError: {exception_type} - {str(ex)}')\n            except Exception as e:\n                exit(f'ERROR getting bucket policy for {bucket_name}: {str(e)}')\n        \n            if not bucket_policy:\n                bucket_policy = new_policy()\n        \n            print(f'Existing policy: {bucket_policy}')\n            bucket_policy['Statement'].append(policy_to_add(bucket_name))\n        \n            try:\n                result = s3.put_bucket_policy(\n                    Bucket=bucket_name,\n                    Policy=json.dumps(bucket_policy, indent=4, default=str),\n                    ExpectedBucketOwner=account_id\n                )\n                print(result)\n            except ClientError as ex:\n                exception_type = ex.response['Error']['Code']\n                exit(f'ERROR: Boto3 s3 ClientError: {exception_type} - {str(ex)}')\n            except Exception as e:\n                exit(f'ERROR putting bucket policy for {bucket_name}: {str(e)}')\n        \n            print(f'New policy: {bucket_policy}')\n        \n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR SetSSLBucketPolicy/Default"
   }
  },
  "SHARRReplaceCodeBuildClearTextCredentials": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-ReplaceCodeBuildClearTextCredentials",
    "Content": "description:  |\n  ### Document Name - SHARR-ReplaceCodeBuildClearTextCredentials\n\n  ## What does this document do?\n  This document is used to replace environment variables containing clear text credentials in a CodeBuild project with Amazon EC2 Systems Manager Parameters.\n\n  ## Input Parameters\n  * ProjectName: (Required) Name of the CodeBuild project (not the ARN).\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n\n  ## Output Parameters\n  * CreateParameters.Parameters - results of the API calls to create SSM parameters\n  * CreateParameters.Policy - result of the API call to create an IAM policy for the project to access the new parameters\n  * CreateParameters.AttachResponse - result of the API call to attach the new IAM policy to the project service role\n  * UpdateProject.Output - result of the API call to update the project environment with the new parameters\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\noutputs:\n  - CreateParameters.Parameters\n  - CreateParameters.Policy\n  - CreateParameters.AttachResponse\n  - UpdateProject.Output\nparameters:\n  ProjectName:\n    type: String\n    description: (Required) The project name (not the ARN).\n    allowedPattern: ^[A-Za-z0-9][A-Za-z0-9\\-_]{1,254}$\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\nmainSteps:\n  - name: BatchGetProjects\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## BatchGetProjects\n      Gets information about one or more build projects.\n    inputs:\n      Service: codebuild\n      Api: BatchGetProjects\n      names: [ \"{{ ProjectName }}\" ]\n    isCritical: true\n    maxAttempts: 2\n    timeoutSeconds: 600\n    outputs:\n      - Name: ProjectInfo\n        Selector: $.projects[0]\n        Type: StringMap\n  - name: CreateParameters\n    action: \"aws:executeScript\"\n    description: |\n      ## CreateParameters\n      Parses project environment variables for credentials.\n      Creates SSM parameters.\n      Returns new project environment variables and SSM parameter information (without values).\n    timeoutSeconds: 600\n    isCritical: true\n    inputs:\n      Runtime: python3.8\n      Handler: replace_credentials\n      InputPayload:\n        ProjectInfo: \"{{ BatchGetProjects.ProjectInfo }}\"\n      Script: |-\n        #!/usr/bin/python\n        ###############################################################################\n        #  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.         #\n        #                                                                             #\n        #  Licensed under the Apache License Version 2.0 (the \"License\"). You may not #\n        #  use this file except in compliance with the License. A copy of the License #\n        #  is located at                                                              #\n        #                                                                             #\n        #      http://www.apache.org/licenses/LICENSE-2.0/                            #\n        #                                                                             #\n        #  or in the \"license\" file accompanying this file. This file is distributed  #\n        #  on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, express #\n        #  or implied. See the License for the specific language governing permis-    #\n        #  sions and limitations under the License.                                   #\n        ###############################################################################\n        from json import dumps\n        from boto3 import client\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        import re\n        \n        boto_config = Config(retries = {'mode': 'standard'})\n        \n        CREDENTIAL_NAMES_UPPER = [\n            'AWS_ACCESS_KEY_ID',\n            'AWS_SECRET_ACCESS_KEY'\n        ]\n        \n        def connect_to_ssm(boto_config):\n            return client('ssm', config = boto_config)\n        \n        def connect_to_iam(boto_config):\n            return client('iam', config = boto_config)\n        \n        def is_clear_text_credential(env_var):\n            if not env_var.get('type') == 'PLAINTEXT':\n                return False\n            return any(env_var.get('name').upper() == credential_name for credential_name in CREDENTIAL_NAMES_UPPER)\n        \n        def get_project_ssm_namespace(project_name):\n            return f'/CodeBuild/{ project_name }'\n        \n        def create_parameter(project_name, env_var):\n            env_var_name = env_var.get('name')\n            parameter_name = f'{ get_project_ssm_namespace(project_name) }/env/{ env_var_name }'\n        \n            ssm_client = connect_to_ssm(boto_config)\n            try:\n                response = ssm_client.put_parameter(\n                    Name = parameter_name,\n                    Description = 'Automatically created by SHARR',\n                    Value = env_var.get(\"value\"),\n                    Type = 'SecureString',\n                    Overwrite = False,\n                    DataType = 'text'\n                )\n            except ClientError as client_exception:\n                exception_type = client_exception.response['Error']['Code']\n                if exception_type == 'ParameterAlreadyExists':\n                    print(f'Parameter { parameter_name } already exists. This remediation may have been run before.')\n                    print('Ignoring exception - remediation continues.')\n                    response = None\n                else:\n                    exit(f'ERROR: Unhandled client exception: { client_exception }')\n            except Exception as e:\n                exit(f'ERROR: could not create SSM parameter { parameter_name }: { str(e) }')\n        \n            return response, parameter_name\n        \n        def create_policy(region, account, partition, project_name):\n            iam_client = connect_to_iam(boto_config)\n            policy_resource_filter = f'arn:{ partition }:ssm:{ region }:{ account }:parameter{ get_project_ssm_namespace(project_name) }/*'\n            policy_document = {\n                'Version': '2012-10-17',\n                'Statement': [\n                    {\n                        'Effect': 'Allow',\n                        'Action': [\n                            'ssm:GetParameter',\n                            'ssm:GetParameters'\n                        ],\n                        'Resource': policy_resource_filter\n                    }\n                ]\n            }\n            policy_name = f'CodeBuildSSMParameterPolicy-{ project_name }-{ region }'\n            try:\n                response = iam_client.create_policy(\n                    Description = \"Automatically created by SHARR\",\n                    PolicyDocument = dumps(policy_document),\n                    PolicyName = policy_name\n                )\n            except ClientError as client_exception:\n                exception_type = client_exception.response['Error']['Code']\n                if exception_type == 'EntityAlreadyExists':\n                    print(f'Policy { \"\" } already exists. This remediation may have been run before.')\n                    print('Ignoring exception - remediation continues.')\n                    # Attach needs to know the ARN of the created policy\n                    response = {\n                        'Policy': {\n                            'Arn': f'arn:{ partition }:iam::{ account }:policy/{ policy_name }'\n                        }\n                    }\n                else:\n                    exit(f'ERROR: Unhandled client exception: { client_exception }')\n            except Exception as e:\n                exit(f'ERROR: could not create access policy { policy_name }: { str(e) }')\n            return response\n        \n        def attach_policy(policy_arn, service_role_name):\n            iam_client = connect_to_iam(boto_config)\n            try:\n                response = iam_client.attach_role_policy(\n                    PolicyArn = policy_arn,\n                    RoleName = service_role_name\n                )\n            except ClientError as client_exception:\n                exit(f'ERROR: Unhandled client exception: { client_exception }')\n            except Exception as e:\n                exit(f'ERROR: could not attach policy { policy_arn } to role { service_role_name }: { str(e) }')\n            return response\n        \n        def parse_project_arn(arn):\n            pattern = re.compile(r'arn:(aws[a-zA-Z-]*):codebuild:([a-z]{2}(?:-gov)?-[a-z]+-\\d):(\\d{12}):project/[A-Za-z0-9][A-Za-z0-9\\-_]{1,254}$')\n            match = pattern.match(arn)\n            if match:\n                partition = match.group(1)\n                region = match.group(2)\n                account = match.group(3)\n                return partition, region, account\n            else:\n                raise ValueError\n        \n        def replace_credentials(event, context):\n            project_info = event.get('ProjectInfo')\n            project_name = project_info.get('name')\n            project_env = project_info.get('environment')\n            project_env_vars = project_env.get('environmentVariables')\n            updated_project_env_vars = []\n            parameters = []\n        \n            for env_var in project_env_vars:\n                if (is_clear_text_credential(env_var)):\n                    parameter_response, parameter_name = create_parameter(project_name, env_var)\n                    updated_env_var = {\n                        'name': env_var.get('name'),\n                        'type': 'PARAMETER_STORE',\n                        'value': parameter_name\n                    }\n                    updated_project_env_vars.append(updated_env_var)\n                    parameters.append(parameter_response)\n                else:\n                    updated_project_env_vars.append(env_var)\n        \n            updated_project_env = project_env\n            updated_project_env['environmentVariables'] = updated_project_env_vars\n        \n            partition, region, account = parse_project_arn(project_info.get('arn'))\n            policy = create_policy(region, account, partition, project_name)\n            service_role_arn = project_info.get('serviceRole')\n            service_role_name = service_role_arn[service_role_arn.rfind('/') + 1:]\n            attach_response = attach_policy(policy['Policy']['Arn'], service_role_name)\n        \n            # datetimes are not serializable, so convert them to ISO 8601 strings\n            policy_datetime_keys = ['CreateDate', 'UpdateDate']\n            for key in policy_datetime_keys:\n                if key in policy['Policy']:\n                    policy['Policy'][key] = policy['Policy'][key].isoformat()\n        \n            return {\n                'UpdatedProjectEnv': updated_project_env,\n                'Parameters': parameters,\n                'Policy': policy,\n                'AttachResponse': attach_response\n            }\n        \n    outputs:\n      - Name: UpdatedProjectEnv\n        Selector: $.Payload.UpdatedProjectEnv\n        Type: StringMap\n      - Name: Parameters\n        Selector: $.Payload.Parameters\n        Type: MapList\n      - Name: Policy\n        Selector: $.Payload.Policy\n        Type: StringMap\n      - Name: AttachResponse\n        Selector: $.Payload.AttachResponse\n        Type: StringMap\n  - name: UpdateProject\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## UpdateProject\n      Changes the settings of a build project.\n    isEnd: true\n    inputs:\n      Service: codebuild\n      Api: UpdateProject\n      name: \"{{ ProjectName }}\"\n      environment: \"{{ CreateParameters.UpdatedProjectEnv }}\"\n    isCritical: true\n    maxAttempts: 2\n    timeoutSeconds: 600\n    outputs:\n      - Name: Output\n        Selector: $.Payload.output\n        Type: StringMap\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR ReplaceCodeBuildClearTextCredentials/Default"
   }
  },
  "SHARRS3BlockDenylist": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-S3BlockDenylist",
    "Content": "description: |\n  ### Document Name - SHARR-S3BlockDenyList\n\n  ## What does this document do?\n  This document adds an explicit DENY to the bucket policy to prevent cross-account access to specific sensitive API calls. By default these are s3:DeleteBucketPolicy, s3:PutBucketAcl, s3:PutBucketPolicy, s3:PutEncryptionConfiguration, and s3:PutObjectAcl.\n\n  ## Input Parameters\n  * BucketName: (Required) Bucket whose bucket policy is to be restricted.\n  * DenyList: (Required) List of permissions to be explicitly denied when the Principal contains a role or user in another account.\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n\n  ## Output Parameters\n  * PutS3BucketPolicyDeny.Output\n\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  BucketName:\n    type: String\n    description: (Required) The bucket name (not the ARN).\n    allowedPattern: (?=^.{3,63}$)(?!^(\\d+\\.)+\\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\\-]*[a-z0-9])\\.)*([a-z0-9]|[a-z0-9][a-z0-9\\-]*[a-z0-9])$)\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  DenyList:\n    type: String\n    description: (Required) Comma-delimited list (string) of permissions to be explicitly denied when the Principal contains a role or user in another account.\n    allowedPattern: '.*'\noutputs:\n  - PutS3BucketPolicyDeny.Output\nmainSteps:\n  -\n    name: PutS3BucketPolicyDeny\n    action: 'aws:executeScript'\n    description: |\n      ## PutS3BucketPolicyDeny\n      Adds an explicit deny to the bucket policy for specific restricted permissions.\n    timeoutSeconds: 600\n    inputs:\n      InputPayload:\n        accountid: '{{global:ACCOUNT_ID}}'\n        bucket: '{{BucketName}}'\n        denylist: '{{DenyList}}'\n      Runtime: python3.8\n      Handler: update_bucket_policy\n      Script: |-\n        #!/usr/bin/python\n        # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n        # SPDX-License-Identifier: Apache-2.0\n        '''\n        Given a bucket name and list of \"sensitive\" IAM permissions that shall not be\n        allowed cross-account, create an explicit deny policy for all cross-account\n        principals, denying access to all IAM permissions in the deny list for all\n        resources.\n        \n        Note:\n        - The deny list is a comma-separated list configured on the Config rule in parameter blacklistedActionPattern\n        '''\n        import json\n        import boto3\n        import copy\n        from botocore.config import Config\n        from botocore.exceptions import ClientError\n        \n        BOTO_CONFIG = Config(\n            retries = {\n                    'mode': 'standard',\n                    'max_attempts': 10\n                }\n            )\n        \n        def connect_to_s3():\n            return boto3.client('s3', config=BOTO_CONFIG)\n        \n        def get_partition():\n            return boto3.client('sts', config=BOTO_CONFIG).get_caller_identity().get('Arn').split(':')[1]\n        \n        class BucketToRemediate:\n            def __init__(self, bucketName):\n                self.bucket_name = bucketName\n                self.get_partition_where_running()\n                self.initialize_bucket_policy_to_none()\n        \n            def __str__(self):\n                return json.dumps(self.__dict__)\n        \n            def initialize_bucket_policy_to_none(self):\n                self.bucket_policy = None\n        \n            def get_partition_where_running(self):\n                self.partition = get_partition()\n        \n            def set_account_id_from_event(self, event):\n                self.account_id = event.get('accountid') or exit('AWS Account not specified')\n        \n            def set_denylist_from_event(self, event):\n                self.denylist = event.get('denylist').split(',') or exit('DenyList is empty or not a comma-delimited string') # Expect a comma seperated list in a string\n        \n            def get_current_bucket_policy(self):\n                try:\n                    self.bucket_policy = connect_to_s3().get_bucket_policy(\n                        Bucket=self.bucket_name,\n                        ExpectedBucketOwner=self.account_id\n                    ).get('Policy')\n        \n                except Exception as e:\n                    print(e)\n                    exit(f'Failed to retrieve the bucket policy: {self.account_id} {self.bucket_name}')\n        \n            def update_bucket_policy(self):\n                try:\n                    connect_to_s3().put_bucket_policy(\n                        Bucket=self.bucket_name,\n                        ExpectedBucketOwner=self.account_id,\n                        Policy=self.bucket_policy\n                    )\n                except Exception as e:\n                    print(e)\n                    exit(f'Failed to store the new bucket policy: {self.account_id} {self.bucket_name}')\n        \n            def __principal_is_asterisk(self, principals):\n                return (True if isinstance(principals, str) and principals == '*' else False)\n        \n            def get_account_principals_from_bucket_policy_statement(self, statement_principals):\n                aws_account_principals = []\n                for principal_type, principal in statement_principals.items():\n                    if principal_type != 'AWS':\n                        continue # not an AWS account\n                    aws_account_principals = principal if isinstance(principal, list) else [ principal ]\n                return aws_account_principals\n        \n            def create_explicit_deny_in_bucket_policy(self):\n                new_bucket_policy = json.loads(self.bucket_policy)\n                deny_statement = DenyStatement(self)\n                for statement in new_bucket_policy['Statement']:\n                    principals = statement.get('Principal', None)\n                    if principals and not self.__principal_is_asterisk(principals):\n                        account_principals = self.get_account_principals_from_bucket_policy_statement(copy.deepcopy(principals))\n                        deny_statement.add_next_principal_to_deny(account_principals, self.account_id)\n        \n                if deny_statement.deny_statement_json:\n                    new_bucket_policy['Statement'].append(deny_statement.deny_statement_json)\n                    self.bucket_policy = json.dumps(new_bucket_policy)\n                    return True\n        \n        class DenyStatement:\n            def __init__(self, bucket_object):\n                self.bucket_object = bucket_object\n                self.initialize_deny_statement()\n        \n            def initialize_deny_statement(self):\n                self.deny_statement_json = {}\n                self.deny_statement_json[\"Effect\"] = \"Deny\"\n                self.deny_statement_json[\"Principal\"] = {\n                    \"AWS\": []\n                }\n                self.deny_statement_json[\"Action\"] = self.bucket_object.denylist\n                self.deny_statement_json[\"Resource\"] = [\n                    f'arn:{self.bucket_object.partition}:s3:::{self.bucket_object.bucket_name}',\n                    f'arn:{self.bucket_object.partition}:s3:::{self.bucket_object.bucket_name}/*',\n                ]\n        \n            def __str__(self):\n                return json.dumps(self.deny_statement_json)\n        \n            def add_next_principal_to_deny(self, principals_to_deny, bucket_account):\n                if len(principals_to_deny) == 0:\n                    return\n                this_principal = principals_to_deny.pop()\n                principal_account = this_principal.split(':')[4]\n                if principal_account and principal_account != bucket_account:\n                    self.add_deny_principal(this_principal)\n        \n                self.add_next_principal_to_deny(principals_to_deny, bucket_account)\n        \n            def add_deny_principal(self, principal_arn):\n                if not principal_arn in self.deny_statement_json[\"Principal\"][\"AWS\"]:\n                    self.deny_statement_json[\"Principal\"][\"AWS\"].append(principal_arn)\n        \n            def add_deny_resource(self, resource_arn):\n                if self.deny_statement_json[\"Resource\"] and not resource_arn in self.deny_statement_json.Resource:\n                    self.deny_statement_json[\"Resource\"].append(resource_arn)\n        \n        def update_bucket_policy(event, context):\n            def __get_bucket_from_event(event):\n                bucket = event.get('bucket') or exit('Bucket not specified')\n                return bucket\n        \n            bucket_to_update = BucketToRemediate(__get_bucket_from_event(event))\n            bucket_to_update.set_denylist_from_event(event)\n            bucket_to_update.set_account_id_from_event(event)\n            bucket_to_update.get_current_bucket_policy()\n            if bucket_to_update.create_explicit_deny_in_bucket_policy():\n                bucket_to_update.update_bucket_policy()\n            else:\n                exit(f'Unable to create an explicit deny statement for {bucket_to_update.bucket_name}')\n        \n    outputs:\n      - Name: Output\n        Selector: $.Payload.output\n        Type: StringMap\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR S3BlockDenylist/Default"
   }
  },
  "SHARREncryptRDSSnapshot": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EncryptRDSSnapshot",
    "Content": "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\n---\nschemaVersion: '0.3'\ndescription: |\n  ### Document Name - SHARR-EncryptRDSSnapshot\n\n  ## What does this document do?\n  This document encrypts an RDS snapshot or cluster snapshot.\n\n  ## Input Parameters\n  * SourceDBSnapshotIdentifier: (Required) The name of the unencrypted RDS snapshot. Note that this snapshot will be deleted as part of this document's execution.\n  * TargetDBSnapshotIdentifier: (Required) The name of the encrypted RDS snapshot to create.\n  * DBSnapshotType: (Required) The type of snapshot (DB or cluster).\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * KmsKeyId: (Optional) ID, ARN or Alias for the AWS KMS Customer-Managed Key (CMK) to use. If no key is specified, the default encryption key for snapshots (`alias/aws/rds`) will be used.\n\n  ## Output Parameters\n  * CopyRdsSnapshotToEncryptedRdsSnapshot.EncryptedSnapshotId: The ID of the encrypted RDS snapshot.\n  * CopyRdsClusterSnapshotToEncryptedRdsClusterSnapshot.EncryptedClusterSnapshotId: The ID of the encrypted RDS cluster snapshot.\n\n  ## Minimum Permissions Required\n  * `rds:CopyDBSnapshot`\n  * `rds:CopyDBClusterSnapshot`\n  * `rds:DescribeDBSnapshots`\n  * `rds:DescribeDBClusterSnapshots`\n  * `rds:DeleteDBSnapshot`\n  * `rds:DeleteDBClusterSnapshot`\n\n  ### Key Permissions\n  If KmsKeyId is a Customer-Managed Key (CMK), then AutomationAssumeRole must have the following permissions on that key:\n  * `kms:DescribeKey`\n  * `kms:CreateGrant`\nassumeRole: '{{AutomationAssumeRole}}'\nparameters:\n  SourceDBSnapshotIdentifier:\n    type: 'String'\n    description: '(Required) The name of the unencrypted RDS snapshot or cluster snapshot to copy.'\n    allowedPattern: '^(?:rds:)?(?!.*--.*)(?!.*-$)[a-zA-Z][a-zA-Z0-9-]{0,254}$'\n  TargetDBSnapshotIdentifier:\n    type: 'String'\n    description: '(Required) The name of the encrypted RDS snapshot or cluster snapshot to create.'\n    allowedPattern: '^(?!.*--.*)(?!.*-$)[a-zA-Z][a-zA-Z0-9-]{0,254}$'\n  DBSnapshotType:\n    type: 'String'\n    allowedValues:\n    - 'snapshot'\n    - 'cluster-snapshot'\n    - 'dbclustersnapshot'\n  AutomationAssumeRole:\n    type: 'String'\n    description: '(Required) The ARN of the role that allows Automation to perform the actions on your behalf.'\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  KmsKeyId:\n    type: 'String'\n    description: '(Optional) ID, ARN or Alias for the AWS KMS Customer-Managed Key (CMK) to use to encrypt the snapshot.'\n    default: 'alias/aws/rds'\n    allowedPattern: '^(?:arn:(?:aws|aws-us-gov|aws-cn):kms:(?:[a-z]{2}(?:-gov)?-[a-z]+-\\d):\\d{12}:)?(?:(?:alias/[A-Za-z0-9/_-]+)|(?:key/(?i:[0-9a-f]{8}-(?:[0-9a-f]{4}-){3}[0-9a-f]{12})))$'\noutputs:\n- 'CopyRdsSnapshotToEncryptedRdsSnapshot.EncryptedSnapshotId'\n- 'CopyRdsClusterSnapshotToEncryptedRdsClusterSnapshot.EncryptedClusterSnapshotId'\nmainSteps:\n- name: 'ChooseSnapshotOrClusterSnapshot'\n  action: 'aws:branch'\n  inputs:\n    Choices:\n    - NextStep: 'CopyRdsSnapshotToEncryptedRdsSnapshot'\n      Variable: '{{DBSnapshotType}}'\n      StringEquals: 'snapshot'\n    - Or:\n      - Variable: '{{DBSnapshotType}}'\n        StringEquals: 'cluster-snapshot'\n      - Variable: '{{DBSnapshotType}}'\n        StringEquals: 'dbclustersnapshot'\n      NextStep: 'CopyRdsClusterSnapshotToEncryptedRdsClusterSnapshot'\n\n- name: 'CopyRdsSnapshotToEncryptedRdsSnapshot'\n  action: 'aws:executeAwsApi'\n  inputs:\n    Service: 'rds'\n    Api: 'CopyDBSnapshot'\n    SourceDBSnapshotIdentifier: '{{SourceDBSnapshotIdentifier}}'\n    TargetDBSnapshotIdentifier: '{{TargetDBSnapshotIdentifier}}'\n    CopyTags: true\n    KmsKeyId: '{{KmsKeyId}}'\n  outputs:\n  - Name: 'EncryptedSnapshotId'\n    Selector: '$.DBSnapshot.DBSnapshotIdentifier'\n    Type: 'String'\n- name: 'VerifyRdsEncryptedSnapshot'\n  action: 'aws:waitForAwsResourceProperty'\n  timeoutSeconds: 14400\n  inputs:\n    Service: 'rds'\n    Api: 'DescribeDBSnapshots'\n    Filters:\n    - Name: 'db-snapshot-id'\n      Values:\n      - '{{CopyRdsSnapshotToEncryptedRdsSnapshot.EncryptedSnapshotId}}'\n    PropertySelector: '$.DBSnapshots[0].Status'\n    DesiredValues:\n    - 'available'\n- name: 'DeleteUnencryptedRdsSnapshot'\n  action: 'aws:executeAwsApi'\n  inputs:\n    Service: 'rds'\n    Api: 'DeleteDBSnapshot'\n    DBSnapshotIdentifier: '{{SourceDBSnapshotIdentifier}}'\n  isEnd: true\n\n- name: 'CopyRdsClusterSnapshotToEncryptedRdsClusterSnapshot'\n  action: 'aws:executeAwsApi'\n  inputs:\n    Service: 'rds'\n    Api: 'CopyDBClusterSnapshot'\n    SourceDBClusterSnapshotIdentifier: '{{SourceDBSnapshotIdentifier}}'\n    TargetDBClusterSnapshotIdentifier: '{{TargetDBSnapshotIdentifier}}'\n    CopyTags: true\n    KmsKeyId: '{{KmsKeyId}}'\n  outputs:\n  - Name: 'EncryptedClusterSnapshotId'\n    Selector: '$.DBClusterSnapshot.DBClusterSnapshotIdentifier'\n    Type: 'String'\n- name: 'VerifyRdsEncryptedClusterSnapshot'\n  action: 'aws:waitForAwsResourceProperty'\n  timeoutSeconds: 14400\n  inputs:\n    Service: 'rds'\n    Api: 'DescribeDBClusterSnapshots'\n    Filters:\n    - Name: 'db-cluster-snapshot-id'\n      Values:\n      - '{{CopyRdsClusterSnapshotToEncryptedRdsClusterSnapshot.EncryptedClusterSnapshotId}}'\n    PropertySelector: '$.DBClusterSnapshots[0].Status'\n    DesiredValues:\n    - 'available'\n- name: 'DeleteUnencryptedRdsClusterSnapshot'\n  action: 'aws:executeAwsApi'\n  inputs:\n    Service: 'rds'\n    Api: 'DeleteDBClusterSnapshot'\n    DBSnapshotIdentifier: '{{SourceDBSnapshotIdentifier}}'\n  isEnd: true\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EncryptRDSSnapshot/Default"
   }
  },
  "SHARRDisablePublicAccessToRedshiftCluster": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-DisablePublicAccessToRedshiftCluster",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n  ### Document name - SHARR-DisablePublicAccessToRedshiftCluster\n\n  ## What does this document do?\n  The runbook disables public accessibility for the Amazon Redshift cluster you specify using the [ModifyCluster]\n  (https://docs.aws.amazon.com/redshift/latest/APIReference/API_ModifyCluster.html) API.\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.\n  * ClusterIdentifier: (Required) The unique identifier of the cluster you want to disable the public accessibility.\n\n  ## Output Parameters\n  * DisableRedshiftPubliclyAccessible.Response: The standard HTTP response from the ModifyCluster API call.\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern:  '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  ClusterIdentifier:\n    type: String\n    description: (Required) The unique identifier of the cluster you want to disable the public accessibility.\n    allowedPattern: \"^(?!.*--)[a-z][a-z0-9-]{0,62}(?<!-)$\"\n\noutputs:\n  - DisableRedshiftPubliclyAccessible.Response\nmainSteps:\n  -\n    name: DisableRedshiftPubliclyAccessible\n    action: aws:executeAwsApi\n    description: |\n      ## DisableRedshiftPubliclyAccessible\n      Disables public accessibility for the cluster specified in the ClusterIdentifer parameter.\n      ## Outputs\n      * Response: The standard HTTP response from the ModifyCluster API call.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: redshift\n      Api: ModifyCluster\n      ClusterIdentifier: \"{{ ClusterIdentifier }}\"\n      PubliclyAccessible: false\n    outputs:\n      - Name: Response\n        Selector: $\n        Type: StringMap\n  - name: WaitForRedshiftClusterAvailability\n    action: aws:waitForAwsResourceProperty\n    description: |\n      ## WaitForRedshiftClusterAvailability\n      Waits for the state of the cluster to change to available.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: redshift\n      Api: DescribeClusters\n      ClusterIdentifier: \"{{ ClusterIdentifier }}\"\n      PropertySelector: $.Clusters[0].ClusterStatus\n      DesiredValues:\n        - \"available\"\n  -\n    name: VerifyRedshiftPubliclyAccessible\n    action: \"aws:assertAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: true\n    description: |\n      ## VerifyRedshiftPubliclyAccessible\n      Confirms the public accessibility setting is disabled on the cluster.\n    inputs:\n      Service: redshift\n      Api: DescribeClusters\n      ClusterIdentifier: \"{{ ClusterIdentifier }}\"\n      PropertySelector: $.Clusters[0].PubliclyAccessible\n      DesiredValues:\n        - \"False\"\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR DisablePublicAccessToRedshiftCluster/Default"
   }
  },
  "SHARREnableRedshiftClusterAuditLogging": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableRedshiftClusterAuditLogging",
    "Content": "description: |\n  ### Document name - AWSConfigRemediation-EnableRedshiftClusterAuditLogging \n\n  ## What does this document do?\n  This automation document enables audit logging on the Amazon Redshift cluster using [EnableLogging](https://docs.aws.amazon.com/redshift/latest/APIReference/API_EnableLogging.html) API call with given bucket name and s3 key prefix. \n\n  ## Input Parameters\n  * ClusterIdentifier: (Required) The unique identifier of the Amazon Redshift cluster on which logging to be started.\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * BucketName: (Required) The name of an existing Amazon S3 bucket where the log files are to be stored.\n  * S3KeyPrefix: (Optional) The prefix applied to the log file names.  \n\n  ## Output Parameters\n  * EnableLoggingWithPrefix.Response: Standard HTTP response of the EnableLogging API.\n  * EnableLoggingWithoutPrefix.Response: Standard HTTP response of the EnableLogging API.\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\noutputs:\n  - EnableLoggingWithoutPrefix.Response\n  - EnableLoggingWithPrefix.Response\nparameters:\n  ClusterIdentifier:\n    type: String\n    description: The unique identifier of the Amazon Redshift cluster on which the logging logging to be started.\n    allowedPattern: \"^(?!.*--)[a-z][a-z0-9-]{0,62}(?<!-)$\"\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  BucketName:\n    type: String\n    description: The name of an existing Amazon S3 bucket where the log files are to be stored.\n    allowedPattern: (?=^.{3,63}$)(?!^(\\d+\\.)+\\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\\-]*[a-z0-9])\\.)*([a-z0-9]|[a-z0-9][a-z0-9\\-]*[a-z0-9])$)\n  S3KeyPrefix:\n    type: String\n    description: The prefix applied to the log file names.\n    allowedPattern: ^[^\"'\\\\ ]{0,512}$\n    default: \"\"\nmainSteps:\n  - name: CheckS3KeyPrefix\n    description: |\n      ## CheckS3KeyPrefix\n      Checks whether S3KeyPrefix provided in the input parameters. \n    action: \"aws:branch\"\n    inputs:\n      Choices:\n        - NextStep: EnableLoggingWithoutPrefix\n          Variable: \"{{S3KeyPrefix}}\"\n          StringEquals: \"\"\n      Default: EnableLoggingWithPrefix\n    isEnd: true\n  - name: EnableLoggingWithoutPrefix\n    nextStep: AssertClusterLoggingEnabled\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## EnableLoggingWithoutPrefix \n      Enables logging on the given Amazon Redshift cluster using the [EnableLogging](https://docs.aws.amazon.com/redshift/latest/APIReference/API_EnableLogging.html) API with given bucket name in input parameters.\n      ## Outputs\n      * Response: Standard HTTP response of the EnableLogging API. \n    inputs:\n      Service: redshift\n      Api: EnableLogging\n      BucketName: \"{{BucketName}}\"\n      ClusterIdentifier: \"{{ ClusterIdentifier }}\"\n    outputs:\n      - Name: Response\n        Selector: $\n        Type: StringMap\n  - name: EnableLoggingWithPrefix\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## EnableLoggingWithPrefix\n      Enables logging on the given Amazon Redshift cluster using the [EnableLogging](https://docs.aws.amazon.com/redshift/latest/APIReference/API_EnableLogging.html) API with given bucket name and s3 key prefix in input parameters.\n      ## Outputs\n      * Response: Standard HTTP response of the EnableLogging API.\n    inputs:\n      Service: redshift\n      Api: EnableLogging\n      BucketName: \"{{BucketName}}\"\n      S3KeyPrefix: \"{{S3KeyPrefix}}\"\n      ClusterIdentifier: \"{{ ClusterIdentifier }}\"\n    outputs:\n      - Name: Response\n        Selector: $\n        Type: StringMap\n  - name: AssertClusterBucketPrefix\n    description: |\n      ## AssertClusterBucketPrefix\n      Verifies whether the value of the \"S3KeyPrefix\" parameter is used for logging for the given Amazon Redshift cluster.\n    action: \"aws:assertAwsResourceProperty\"\n    inputs:\n      Service: redshift\n      Api: DescribeLoggingStatus\n      ClusterIdentifier: \"{{ ClusterIdentifier }}\"\n      PropertySelector: $.S3KeyPrefix\n      DesiredValues:\n        - \"{{S3KeyPrefix}}/\"\n  - name: AssertClusterLoggingEnabled\n    description: |\n      ## AssertClusterLoggingEnabled\n      Verifies whether the \"LoggingEnabled\" property is set to \"True\" for the given Amazon Redshift cluster.\n    action: \"aws:assertAwsResourceProperty\"\n    inputs:\n      Service: redshift\n      Api: DescribeLoggingStatus\n      ClusterIdentifier: \"{{ ClusterIdentifier }}\"\n      PropertySelector: $.LoggingEnabled\n      DesiredValues:\n        - \"True\"\n  - name: AssertClusterLoggingBucket\n    description: |\n      ## AssertClusterLoggingBucket\n      Checks whether the value of the \"BucketName\" parameter is used for the audit logging configuration of the given Amazon Redshift cluster.\n    action: \"aws:assertAwsResourceProperty\"\n    inputs:\n      Service: redshift\n      Api: DescribeLoggingStatus\n      ClusterIdentifier: \"{{ ClusterIdentifier }}\"\n      PropertySelector: $.BucketName\n      DesiredValues:\n        - \"{{BucketName}}\"\n    isEnd: true\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableRedshiftClusterAuditLogging/Default"
   }
  },
  "SHARREnableAutomaticVersionUpgradeOnRedshiftCluster": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableAutomaticVersionUpgradeOnRedshiftCluster",
    "Content": "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\n---\nschemaVersion: '0.3'\ndescription: |\n  ### Document name - SHARR-EnableAutomaticVersionUpgradeOnRedshiftCluster\n\n  ## What does this document do?\n  The runbook enables automatic version upgrade on a Redshift cluster.\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * ClusterIdentifier: (Required) The unique identifier of the cluster.\n  * AllowVersionUpgrade: (Optional) Whether to allow version upgrade on the cluster.\n\n  ## Output Parameters\n  * EnableAutomaticVersionUpgrade.Response: The response of the API call to enable automatic version upgrade on the cluster.\nassumeRole: '{{AutomationAssumeRole}}'\nparameters:\n  AutomationAssumeRole:\n    type: 'String'\n    description: '(Required) The ARN of the role that allows Automation to perform the actions on your behalf.'\n    allowedPattern:  '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  ClusterIdentifier:\n    type: 'String'\n    description: '(Required) The unique identifier of the cluster.'\n    allowedPattern: '^(?!.*--)[a-z][a-z0-9-]{0,62}(?<!-)$'\n  AllowVersionUpgrade:\n    type: 'Boolean'\n    description: (Optional) Whether to allow version upgrade on the cluster.\n    default: true\noutputs:\n- 'EnableAutomaticVersionUpgrade.Response'\nmainSteps:\n- name: 'EnableAutomaticVersionUpgrade'\n  action: 'aws:executeAwsApi'\n  inputs:\n    Service: 'redshift'\n    Api: 'ModifyCluster'\n    ClusterIdentifier: '{{ClusterIdentifier}}'\n    AllowVersionUpgrade: '{{AllowVersionUpgrade}}'\n  outputs:\n  - Name: 'Response'\n    Selector: '$'\n    Type: 'StringMap'\n- name: 'WaitForClusterAvailability'\n  action: 'aws:waitForAwsResourceProperty'\n  timeoutSeconds: 600\n  inputs:\n    Service: 'redshift'\n    Api: 'DescribeClusters'\n    ClusterIdentifier: '{{ClusterIdentifier}}'\n    PropertySelector: '$.Clusters[0].ClusterStatus'\n    DesiredValues:\n    - 'available'\n- name: 'CastAllowVersionUpgradeToString'\n  action: 'aws:executeScript'\n  inputs:\n    Runtime: 'python3.8'\n    Handler: 'event_handler'\n    InputPayload:\n      AllowVersionUpgrade: '{{AllowVersionUpgrade}}'\n    Script: >\n      def event_handler(event, context):\n          return str(event['AllowVersionUpgrade'])\n  outputs:\n  - Name: 'AllowVersionUpgradeString'\n    Selector: '$.Payload'\n    Type: 'String'\n- name: 'VerifyAutomaticVersionUpgrade'\n  action: 'aws:assertAwsResourceProperty'\n  inputs:\n    Service: 'redshift'\n    Api: 'DescribeClusters'\n    ClusterIdentifier: '{{ClusterIdentifier}}'\n    PropertySelector: '$.Clusters[0].AllowVersionUpgrade'\n    DesiredValues:\n    - '{{CastAllowVersionUpgradeToString.AllowVersionUpgradeString}}'\n  isEnd: true\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableAutomaticVersionUpgradeOnRedshiftCluster/Default"
   }
  },
  "SHARREnableAutomaticSnapshotsOnRedshiftCluster": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableAutomaticSnapshotsOnRedshiftCluster",
    "Content": "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\n---\nschemaVersion: '0.3'\ndescription: |\n  ### Document name - SHARR-EnableAutomaticSnapshotsOnRedshiftCluster\n\n  ## What does this document do?\n  The runbook enables automatic snapshots on a Redshift cluster.\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * ClusterIdentifier: (Required) The unique identifier of the cluster.\n  * RetentionPeriod: (Optional) The minimum retention period for the automatic snapshots in days.\n\n  ## Output Parameters\n  * QueryRetentionPeriod.CurrentRetentionPeriod: The retention period of the cluster in days at the start of the automation.\n  * ModifyRetentionPeriod.Response: The response of the API call to modify the retention period of the cluster.\nassumeRole: '{{AutomationAssumeRole}}'\nparameters:\n  AutomationAssumeRole:\n    type: 'String'\n    description: '(Required) The ARN of the role that allows Automation to perform the actions on your behalf.'\n    allowedPattern:  '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  ClusterIdentifier:\n    type: 'String'\n    description: '(Required) The unique identifier of the cluster.'\n    allowedPattern: '^(?!.*--)[a-z][a-z0-9-]{0,62}(?<!-)$'\n  MinRetentionPeriod:\n    type: 'Integer'\n    description: (Optional) The minimum retention period for the automatic snapshots in days.\n    default: 7\noutputs:\n- 'QueryRetentionPeriod.CurrentRetentionPeriod'\n- 'ModifyRetentionPeriod.Response'\nmainSteps:\n- name: 'QueryRetentionPeriod'\n  action: 'aws:executeAwsApi'\n  inputs:\n    Service: 'redshift'\n    Api: 'DescribeClusters'\n    ClusterIdentifier: '{{ClusterIdentifier}}'\n  outputs:\n  - Name: 'CurrentRetentionPeriod'\n    Selector: '$.Clusters[0].AutomatedSnapshotRetentionPeriod'\n    Type: Integer\n- name: 'ChooseModifyRetentionPeriod'\n  action: 'aws:branch'\n  inputs:\n    Choices:\n    - NextStep: 'CastCurrentRetentionPeriodToString'\n      Variable: '{{QueryRetentionPeriod.CurrentRetentionPeriod}}'\n      NumericGreaterOrEquals: '{{MinRetentionPeriod}}'\n    Default: 'ModifyRetentionPeriod'\n\n- name: 'CastCurrentRetentionPeriodToString'\n  action: 'aws:executeScript'\n  inputs:\n    Runtime: 'python3.8'\n    Handler: 'event_handler'\n    InputPayload:\n      RetentionPeriod: '{{QueryRetentionPeriod.CurrentRetentionPeriod}}'\n    Script: >\n      def event_handler(event, context):\n          return str(event['RetentionPeriod'])\n  outputs:\n  - Name: 'CurrentRetentionPeriodString'\n    Selector: '$.Payload'\n    Type: 'String'\n- name: 'VerifyCurrentRetentionPeriod'\n  action: 'aws:assertAwsResourceProperty'\n  inputs:\n    Service: 'redshift'\n    Api: 'DescribeClusters'\n    ClusterIdentifier: '{{ClusterIdentifier}}'\n    PropertySelector: '$.Clusters[0].AutomatedSnapshotRetentionPeriod'\n    DesiredValues:\n    - '{{CastCurrentRetentionPeriodToString.CurrentRetentionPeriodString}}'\n  isEnd: true\n\n- name: 'ModifyRetentionPeriod'\n  action: 'aws:executeAwsApi'\n  inputs:\n    Service: 'redshift'\n    Api: 'ModifyCluster'\n    ClusterIdentifier: '{{ClusterIdentifier}}'\n    AutomatedSnapshotRetentionPeriod: '{{MinRetentionPeriod}}'\n  outputs:\n  - Name: 'Response'\n    Selector: '$'\n    Type: 'StringMap'\n- name: 'WaitForClusterAvailability'\n  action: 'aws:waitForAwsResourceProperty'\n  timeoutSeconds: 600\n  inputs:\n    Service: 'redshift'\n    Api: 'DescribeClusters'\n    ClusterIdentifier: '{{ClusterIdentifier}}'\n    PropertySelector: '$.Clusters[0].ClusterStatus'\n    DesiredValues:\n    - 'available'\n- name: 'CastRetentionPeriodToString'\n  action: 'aws:executeScript'\n  inputs:\n    Runtime: 'python3.8'\n    Handler: 'event_handler'\n    InputPayload:\n      RetentionPeriod: '{{MinRetentionPeriod}}'\n    Script: >\n      def event_handler(event, context):\n          return str(event['RetentionPeriod'])\n  outputs:\n  - Name: 'MinRetentionPeriodString'\n    Selector: '$.Payload'\n    Type: 'String'\n- name: 'VerifyModifiedRetentionPeriod'\n  action: 'aws:assertAwsResourceProperty'\n  inputs:\n    Service: 'redshift'\n    Api: 'DescribeClusters'\n    ClusterIdentifier: '{{ClusterIdentifier}}'\n    PropertySelector: '$.Clusters[0].AutomatedSnapshotRetentionPeriod'\n    DesiredValues:\n    - '{{CastRetentionPeriodToString.MinRetentionPeriodString}}'\n  isEnd: true\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableAutomaticSnapshotsOnRedshiftCluster/Default"
   }
  },
  "SHARRConfigureS3BucketPublicAccessBlock": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-ConfigureS3BucketPublicAccessBlock",
    "Content": "description:  |\n  ### Document Name - AWSConfigRemediation-ConfigureS3BucketPublicAccessBlock\n\n  ## What does this document do?\n  This document is used to create or modify the PublicAccessBlock configuration for an Amazon S3 bucket.\n\n  ## Input Parameters\n  * BucketName: (Required) Name of the S3 bucket (not the ARN).\n  * RestrictPublicBuckets: (Optional) Specifies whether Amazon S3 should restrict public bucket policies for this bucket. Setting this element to TRUE restricts access to this bucket to only AWS services and authorized users within this account if the bucket has a public policy.\n    * Default: \"true\"\n  * BlockPublicAcls: (Optional) Specifies whether Amazon S3 should block public access control lists (ACLs) for this bucket and objects in this bucket.\n    * Default: \"true\"\n  * IgnorePublicAcls: (Optional) Specifies whether Amazon S3 should ignore public ACLs for this bucket and objects in this bucket. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on this bucket and objects in this bucket.\n    * Default: \"true\"\n  * BlockPublicPolicy: (Optional) Specifies whether Amazon S3 should block public bucket policies for this bucket. Setting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket policy allows public access.\n    * Default: \"true\"\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n\n  ## Output Parameters\n  * GetBucketPublicAccessBlock.Output - JSON formatted response from the GetPublicAccessBlock API call\n\n  ## Note: this is a local copy of the AWS-owned document to enable support in aws-cn and aws-us-gov partitions.\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\noutputs:\n  - GetBucketPublicAccessBlock.Output\nparameters:\n  BucketName:\n    type: String\n    description: (Required) The bucket name (not the ARN).\n    allowedPattern: (?=^.{3,63}$)(?!^(\\d+\\.)+\\d+$)(^(([a-z0-9]|[a-z0-9][a-z0-9\\-]*[a-z0-9])\\.)*([a-z0-9]|[a-z0-9][a-z0-9\\-]*[a-z0-9])$)\n  RestrictPublicBuckets:\n    type: Boolean\n    description: (Optional) Specifies whether Amazon S3 should restrict public bucket policies for this bucket. Setting this element to TRUE restricts access to this bucket to only AWS services and authorized users within this account if the bucket has a public policy.\n    default: true\n    allowedValues:\n      - true\n      - false\n  BlockPublicAcls:\n    type: Boolean\n    description: (Optional) Specifies whether Amazon S3 should block public access control lists (ACLs) for this bucket and objects in this bucket.\n    default: true\n    allowedValues:\n      - true\n      - false\n  IgnorePublicAcls:\n    type: Boolean\n    description: (Optional) Specifies whether Amazon S3 should ignore public ACLs for this bucket and objects in this bucket. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on this bucket and objects in this bucket.\n    default: true\n    allowedValues:\n      - true\n      - false\n  BlockPublicPolicy:\n    type: Boolean\n    description: (Optional) Specifies whether Amazon S3 should block public bucket policies for this bucket. Setting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket policy allows public access.\n    default: true\n    allowedValues:\n      - true\n      - false\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\nmainSteps:\n  - name: PutBucketPublicAccessBlock\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## PutBucketPublicAccessBlock\n      Creates or modifies the PublicAccessBlock configuration for a S3 Bucket.\n    isEnd: false\n    inputs:\n      Service: s3\n      Api: PutPublicAccessBlock\n      Bucket: \"{{BucketName}}\"\n      PublicAccessBlockConfiguration:\n        RestrictPublicBuckets: \"{{ RestrictPublicBuckets }}\"\n        BlockPublicAcls: \"{{ BlockPublicAcls }}\"\n        IgnorePublicAcls: \"{{ IgnorePublicAcls }}\"\n        BlockPublicPolicy: \"{{ BlockPublicPolicy }}\"\n    isCritical: true\n    maxAttempts: 2\n    timeoutSeconds: 600\n  - name: GetBucketPublicAccessBlock\n    action: \"aws:executeScript\"\n    description: |\n      ## GetBucketPublicAccessBlock\n      Retrieves the S3 PublicAccessBlock configuration for a S3 Bucket.\n      ## Outputs\n      * Output: JSON formatted response from the GetPublicAccessBlock API call.\n    timeoutSeconds: 600\n    isCritical: true\n    isEnd: true\n    inputs:\n      Runtime: python3.8\n      Handler: validate_s3_bucket_publicaccessblock\n      InputPayload:\n        Bucket: \"{{BucketName}}\"\n        RestrictPublicBuckets: \"{{ RestrictPublicBuckets }}\"\n        BlockPublicAcls: \"{{ BlockPublicAcls }}\"\n        IgnorePublicAcls: \"{{ IgnorePublicAcls }}\"\n        BlockPublicPolicy: \"{{ BlockPublicPolicy }}\"\n      Script: |-\n        import boto3\n\n        def validate_s3_bucket_publicaccessblock(event, context):\n          s3_client = boto3.client(\"s3\")\n          bucket = event[\"Bucket\"]\n          restrict_public_buckets = event[\"RestrictPublicBuckets\"]\n          block_public_acls = event[\"BlockPublicAcls\"]\n          ignore_public_acls = event[\"IgnorePublicAcls\"]\n          block_public_policy = event[\"BlockPublicPolicy\"]\n\n          output = s3_client.get_public_access_block(Bucket=bucket)\n          updated_block_acl = output[\"PublicAccessBlockConfiguration\"][\"BlockPublicAcls\"]\n          updated_ignore_acl = output[\"PublicAccessBlockConfiguration\"][\"IgnorePublicAcls\"]\n          updated_block_policy = output[\"PublicAccessBlockConfiguration\"][\"BlockPublicPolicy\"]\n          updated_restrict_buckets = output[\"PublicAccessBlockConfiguration\"][\"RestrictPublicBuckets\"]\n\n          if updated_block_acl == block_public_acls and updated_ignore_acl == ignore_public_acls \\\n          and updated_block_policy == block_public_policy and updated_restrict_buckets == restrict_public_buckets:\n            return {\n              \"output\":\n                {\n                  \"message\": \"Bucket public access block configuration successfully set.\",\n                  \"configuration\": output[\"PublicAccessBlockConfiguration\"]\n                }\n            }\n          else:\n              info = \"CONFIGURATION VALUES DO NOT MATCH WITH PARAMETERS PROVIDED VALUES RestrictPublicBuckets: {}, BlockPublicAcls: {}, IgnorePublicAcls: {}, BlockPublicPolicy: {}\".format(\n                        restrict_public_buckets,\n                        block_public_acls,\n                        ignore_public_acls,\n                        block_public_policy\n                      )\n              raise Exception(info)\n    outputs:\n      - Name: Output\n        Selector: $.Payload.output\n        Type: StringMap\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR ConfigureS3BucketPublicAccessBlock/Default"
   }
  },
  "SHARRConfigureS3PublicAccessBlock": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-ConfigureS3PublicAccessBlock",
    "Content": "description: |\n  ### Document Name - AWSConfigRemediation-ConfigureS3PublicAccessBlock\n\n  ## What does this document do?\n  This document is used to create or modify the S3 [PublicAccessBlock](https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html#access-control-block-public-access-options) configuration for an AWS account.\n\n  ## Input Parameters\n  * AccountId: (Required) Account ID of the account for which the S3 Account Public Access Block is to be configured.\n  * RestrictPublicBuckets: (Optional) Specifies whether Amazon S3 should restrict public bucket policies for buckets in this account. Setting this element to TRUE restricts access to buckets with public policies to only AWS services and authorized users within this account.\n    * Default: \"true\"\n  * BlockPublicAcls: (Optional) Specifies whether Amazon S3 should block public access control lists (ACLs) for buckets in this account.\n    * Default: \"true\"\n  * IgnorePublicAcls: (Optional) Specifies whether Amazon S3 should ignore public ACLs for buckets in this account. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on buckets in this account and any objects that they contain.\n    * Default: \"true\"\n  * BlockPublicPolicy: (Optional) Specifies whether Amazon S3 should block public bucket policies for buckets in this account. Setting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket policy allows public access.\n    * Default: \"true\"\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n\n  ## Output Parameters\n  * GetPublicAccessBlock.Output - JSON formatted response from the GetPublicAccessBlock API call.\n\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AccountId:\n    type: String\n    description: (Required) The account ID for the AWS account whose PublicAccessBlock configuration you want to set.\n    allowedPattern: ^\\d{12}$\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  RestrictPublicBuckets:\n    type: Boolean\n    description: (Optional) Specifies whether Amazon S3 should restrict public bucket policies for buckets in this account. Setting this element to TRUE restricts access to buckets with public policies to only AWS services and authorized users within this account.\n    default: true\n  BlockPublicAcls:\n    type: Boolean\n    description: (Optional) Specifies whether Amazon S3 should block public access control lists (ACLs) for buckets in this account.\n    default: true\n  IgnorePublicAcls:\n    type: Boolean\n    description: (Optional) Specifies whether Amazon S3 should ignore public ACLs for buckets in this account. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on buckets in this account and any objects that they contain.\n    default: true\n  BlockPublicPolicy:\n    type: Boolean\n    description: (Optional) Specifies whether Amazon S3 should block public bucket policies for buckets in this account. Setting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket policy allows public access.\n    default: true\noutputs:\n  - GetPublicAccessBlock.Output\nmainSteps:\n  -\n    name: PutAccountPublicAccessBlock\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## PutAccountPublicAccessBlock\n      Creates or modifies the S3 PublicAccessBlock configuration for an AWS account.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: s3control\n      Api: PutPublicAccessBlock\n      AccountId: \"{{ AccountId }}\"\n      PublicAccessBlockConfiguration:\n        RestrictPublicBuckets: \"{{ RestrictPublicBuckets }}\"\n        BlockPublicAcls: \"{{ BlockPublicAcls }}\"\n        IgnorePublicAcls: \"{{ IgnorePublicAcls }}\"\n        BlockPublicPolicy: \"{{ BlockPublicPolicy }}\"\n    outputs:\n      - Name: PutAccountPublicAccessBlockResponse\n        Selector: $\n        Type: StringMap\n  -\n    name: GetPublicAccessBlock\n    action: \"aws:executeScript\"\n    description: |\n      ## GetPublicAccessBlock\n      Retrieves the S3 PublicAccessBlock configuration for an AWS account.\n      ## Outputs\n      * Output: JSON formatted response from the GetPublicAccessBlock API call.\n    timeoutSeconds: 600\n    isEnd: true\n    inputs:\n      Runtime: python3.8\n      Handler: handler\n      InputPayload:\n        AccountId: \"{{ AccountId }}\"\n        RestrictPublicBuckets: \"{{ RestrictPublicBuckets }}\"\n        BlockPublicAcls: \"{{ BlockPublicAcls }}\"\n        IgnorePublicAcls: \"{{ IgnorePublicAcls }}\"\n        BlockPublicPolicy: \"{{ BlockPublicPolicy }}\"\n      Script: |-\n        import boto3\n        from time import sleep\n\n        def verify_s3_public_access_block(account_id, restrict_public_buckets, block_public_acls, ignore_public_acls, block_public_policy):\n           s3control_client = boto3.client('s3control')\n           wait_time = 30\n           max_time = 480\n           retry_count = 1\n           max_retries = max_time/wait_time\n           while retry_count <= max_retries:\n               sleep(wait_time)\n               retry_count = retry_count + 1\n               get_public_access_response = s3control_client.get_public_access_block(AccountId=account_id)\n               updated_block_acl = get_public_access_response['PublicAccessBlockConfiguration']['BlockPublicAcls']\n               updated_ignore_acl = get_public_access_response['PublicAccessBlockConfiguration']['IgnorePublicAcls']\n               updated_block_policy = get_public_access_response['PublicAccessBlockConfiguration']['BlockPublicPolicy']\n               updated_restrict_buckets = get_public_access_response['PublicAccessBlockConfiguration']['RestrictPublicBuckets']\n               if updated_block_acl == block_public_acls and updated_ignore_acl == ignore_public_acls \\\n                         and updated_block_policy == block_public_policy and updated_restrict_buckets == restrict_public_buckets:\n                           return {\n                               \"output\": {\n                                   \"message\": \"Verification successful. S3 Public Access Block Updated.\",\n                                   \"HTTPResponse\": get_public_access_response[\"PublicAccessBlockConfiguration\"]\n                               },\n                           }\n           raise Exception(\n                 \"VERFICATION FAILED. S3 GetPublicAccessBlock CONFIGURATION VALUES \"\n                 \"DO NOT MATCH WITH PARAMETERS PROVIDED VALUES \"\n                 \"RestrictPublicBuckets: {}, BlockPublicAcls: {}, IgnorePublicAcls: {}, BlockPublicPolicy: {}\"\n                 .format(updated_restrict_buckets, updated_block_acl, updated_ignore_acl, updated_block_policy)\n           )\n\n        def handler(event, context):\n          account_id = event[\"AccountId\"]\n          restrict_public_buckets = event[\"RestrictPublicBuckets\"]\n          block_public_acls = event[\"BlockPublicAcls\"]\n          ignore_public_acls = event[\"IgnorePublicAcls\"]\n          block_public_policy = event[\"BlockPublicPolicy\"]\n          return verify_s3_public_access_block(account_id, restrict_public_buckets, block_public_acls, ignore_public_acls, block_public_policy)\n\n    outputs:\n      - Name: Output\n        Selector: $.Payload.output\n        Type: StringMap\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR ConfigureS3PublicAccessBlock/Default"
   }
  },
  "SHARREnableCloudTrailLogFileValidation": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableCloudTrailLogFileValidation",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n  ### Document name - AWSConfigRemediation-EnableCloudTrailLogFileValidation\n\n  ## What does this document do?\n  This runbook enables log file validation for your AWS CloudTrail trail using the [UpdateTrail](https://docs.aws.amazon.com/awscloudtrail/latest/APIReference/API_UpdateTrail.html) API.\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.\n  * TrailName: (Required) The name or Amazon Resource Name (ARN) of the trail you want to enable log file validation for.\n\n  ## Output Parameters\n  * UpdateTrail.Output: The response of the UpdateTrail API call.\n\n  ## Note: this is a local copy of the AWS-owned document to enable support in aws-cn and aws-us-gov partitions.\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  TrailName:\n    type: String\n    description: (Required) The name or Amazon Resource Name (ARN) of the trail you want to enable log file validation for.\n    allowedPattern: (^arn:(aws[a-zA-Z-]*)?:cloudtrail:[a-z0-9-]+:\\d{12}:trail\\/(?![-_.])(?!.*[-_.]{2})(?!.*[-_.]$)(?!^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$)[-\\w.]{3,128}$)|(^(?![-_.])(?!.*[-_.]{2})(?!.*[-_.]$)(?!^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$)[-\\w.]{3,128}$)\noutputs:\n  - UpdateTrail.Output\nmainSteps:\n  - name: UpdateTrail\n    action: aws:executeAwsApi\n    description: |\n      ## UpdateTrail\n      Enables log file validation for the AWS CloudTrail trail you specify in the TrailName parameter.\n      ## Outputs\n      * Output: Response from the UpdateTrail API call.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: cloudtrail\n      Api: UpdateTrail\n      Name: \"{{ TrailName }}\"\n      EnableLogFileValidation: True\n    outputs:\n      - Name: Output\n        Selector: $\n        Type: StringMap\n  - name: VerifyTrail\n    action: aws:assertAwsResourceProperty\n    description: |\n      ## VerifyTrail\n      Verifies log file validation is enabled for your trail.\n    timeoutSeconds: 600\n    isEnd: true\n    inputs:\n      Service: cloudtrail\n      Api: GetTrail\n      Name: \"{{ TrailName }}\"\n      PropertySelector: $.Trail.LogFileValidationEnabled\n      DesiredValues:\n        - \"True\"\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableCloudTrailLogFileValidation/Default"
   }
  },
  "SHARREnableEbsEncryptionByDefault": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableEbsEncryptionByDefault",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n   ### Document Name - AWSConfigRemediation-EnableEbsEncryptionByDefault\n\n   ## What does this document do?\n   This document enables EBS encryption by default for an AWS account in the current region using the [EnableEbsEncryptionByDefault](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_EnableEbsEncryptionByDefault.html) API.\n\n   ## Input Parameters\n   * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n\n   ## Output Parameters\n   * ModifyAccount.EnableEbsEncryptionByDefaultResponse: JSON formatted response from the EnableEbsEncryptionByDefault API.\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\noutputs:\n  - ModifyAccount.EnableEbsEncryptionByDefaultResponse\nmainSteps:\n  -\n    name: ModifyAccount\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## ModifyAccount\n      Enables EBS encryption by default for the account in the current region.\n      ## Outputs\n      * EnableEbsEncryptionByDefaultResponse: Response from the EnableEbsEncryptionByDefault API.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: ec2\n      Api: EnableEbsEncryptionByDefault\n    outputs:\n      - Name: EnableEbsEncryptionByDefaultResponse\n        Selector: $\n        Type: StringMap\n  -\n    name: VerifyEbsEncryptionByDefault\n    action: \"aws:assertAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: true\n    description: |\n      ## VerifyEbsEncryptionByDefault\n      Checks if EbsEncryptionByDefault is enabled correctly from the previous step.\n    inputs:\n      Service: ec2\n      Api: GetEbsEncryptionByDefault\n      PropertySelector: \"$.EbsEncryptionByDefault\"\n      DesiredValues:\n        - \"True\"\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableEbsEncryptionByDefault/Default"
   }
  },
  "SHARREnableEnhancedMonitoringOnRDSInstance": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableEnhancedMonitoringOnRDSInstance",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n   ### Document Name - AWSConfigRemediation-EnableEnhancedMonitoringOnRDSInstance\n\n   ## What does this document do?\n   This document is used to enable enhanced monitoring on an RDS Instance using the input parameter DB Instance resourceId.\n\n   ## Input Parameters\n   * ResourceId: (Required) Resource ID of the RDS DB Instance.\n   * MonitoringInterval: (Optional)\n      * The interval, in seconds, between points when Enhanced Monitoring metrics are collected for the DB instance.\n      * If MonitoringRoleArn is specified, then you must also set MonitoringInterval to a value other than 0.\n      * Valid Values: 1, 5, 10, 15, 30, 60\n      * Default: 60\n   * MonitoringRoleArn: (Required) The ARN for the IAM role that permits RDS to send enhanced monitoring metrics to Amazon CloudWatch Logs.\n   * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n\n   ## Output Parameters\n   * EnableEnhancedMonitoring.DbInstance - The standard HTTP response from the ModifyDBInstance API.\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  ResourceId:\n    type: String\n    description: (Required) Resource ID of the Amazon RDS instance for which Enhanced Monitoring needs to be enabled.\n    allowedPattern: \"db-[A-Z0-9]{26}\"\n  MonitoringInterval:\n    type: Integer\n    description: (Optional) The interval, in seconds, between points when Enhanced Monitoring metrics are collected for the DB instance.\n    default: 60\n    allowedValues:\n      - 1\n      - 5\n      - 10\n      - 15\n      - 30\n      - 60\n  MonitoringRoleArn:\n    type: String\n    description: (Required) The ARN for the IAM role that permits RDS to send enhanced monitoring metrics to Amazon CloudWatch Logs.\n    allowedPattern: ^arn:(aws[a-zA-Z-]*)?:iam::\\d{12}:role/[a-zA-Z0-9+=,.@_/-]+$\noutputs:\n  - EnableEnhancedMonitoring.DbInstance\nmainSteps:\n  -\n    name: DescribeDBInstances\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## DescribeDBInstances\n        Makes describeDBInstances API call using RDS Instance DbiResourceId to get DBInstanceId.\n      ## Outputs\n      * DbInstanceIdentifier: DBInstance Identifier of the RDS Instance.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      Filters:\n        - Name: \"dbi-resource-id\"\n          Values:\n            - \"{{ ResourceId }}\"\n    outputs:\n      - Name: DbInstanceIdentifier\n        Selector: $.DBInstances[0].DBInstanceIdentifier\n        Type: String\n  -\n    name: VerifyDBInstanceStatus\n    action: \"aws:assertAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: false\n    description: |\n      ## VerifyDBInstanceStatus\n      Verifies if DB Instance status is available before enabling enhanced monitoring.\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      DBInstanceIdentifier: \"{{ DescribeDBInstances.DbInstanceIdentifier }}\"\n      PropertySelector: \"$.DBInstances[0].DBInstanceStatus\"\n      DesiredValues:\n        - \"available\"\n  -\n    name: EnableEnhancedMonitoring\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## EnableEnhancedMonitoring\n        Makes ModifyDBInstance API call to enable Enhanced Monitoring on the RDS Instance\n        using the DBInstanceId from the previous action.\n      ## Outputs\n        * DbInstance: The standard HTTP response from the ModifyDBInstance API.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n       Service: rds\n       Api: ModifyDBInstance\n       ApplyImmediately: False\n       DBInstanceIdentifier: \"{{ DescribeDBInstances.DbInstanceIdentifier }}\"\n       MonitoringInterval: \"{{ MonitoringInterval }}\"\n       MonitoringRoleArn: \"{{ MonitoringRoleArn }}\"\n    outputs:\n      - Name: DbInstance\n        Selector: $\n        Type: StringMap\n  -\n    name: VerifyEnhancedMonitoringEnabled\n    action: \"aws:executeScript\"\n    description: |\n      ## VerifyEnhancedMonitoringEnabled\n      Checks that the enhanced monitoring is enabled on RDS Instance in the previous step exists.\n      ## Outputs\n      * Output: The standard HTTP response from the ModifyDBInstance API.\n    isEnd: true\n    timeoutSeconds: 600\n    inputs:\n      Runtime: python3.8\n      Handler: handler\n      InputPayload:\n        MonitoringInterval: \"{{ MonitoringInterval }}\"\n        DBIdentifier: \"{{ DescribeDBInstances.DbInstanceIdentifier }}\"\n      Script: |-\n        import boto3\n        import time\n\n        def handler(event, context):\n            rds_client = boto3.client(\"rds\")\n            db_instance_id = event[\"DBIdentifier\"]\n            monitoring_interval = event[\"MonitoringInterval\"]\n\n            try:\n                rds_waiter = rds_client.get_waiter(\"db_instance_available\")\n                rds_waiter.wait(DBInstanceIdentifier=db_instance_id)\n\n                db_instances = rds_client.describe_db_instances(\n                    DBInstanceIdentifier=db_instance_id)\n\n                for db_instance in db_instances.get(\"DBInstances\", [{}]):\n                    db_monitoring_interval = db_instance.get(\"MonitoringInterval\")\n\n                if db_monitoring_interval == monitoring_interval:\n                    return {\n                              \"output\": db_instances[\"ResponseMetadata\"]\n                            }\n                else:\n                    info = \"VERIFICATION FAILED. RDS INSTANCE MONITORING INTERVAL {} IS NOT ENABLED WITH THE REQUIRED VALUE {}\".format(\n                            db_monitoring_interval, monitoring_interval)\n                    raise Exception(info)\n            except Exception as e:\n                raise e\n    outputs:\n      - Name: Output\n        Selector: $.Payload.output\n        Type: StringMap\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableEnhancedMonitoringOnRDSInstance/Default"
   }
  },
  "SHARREnableKeyRotation": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableKeyRotation",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n  ### Document name - AWSConfigRemediation-EnableKeyRotation\n\n  ## What does this document do?\n  This document enables automatic key rotation for the given AWS Key Management Service (KMS) symmetric customer master key(CMK) using [EnableKeyRotation](https://docs.aws.amazon.com/kms/latest/APIReference/API_EnableKeyRotation.html) API.\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * KeyId: (Required) The Key ID of the AWS KMS symmetric CMK.\n\n  ## Output Parameters\n  * EnableKeyRotation.EnableKeyRotationResponse: The standard HTTP response from the EnableKeyRotation API.\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  KeyId:\n    type: String\n    description: (Required) The Key ID of the AWS KMS symmetric CMK.\n    allowedPattern: \"[a-z0-9-]{1,2048}\"\n\noutputs:\n  - EnableKeyRotation.EnableKeyRotationResponse\nmainSteps:\n  -\n    name: EnableKeyRotation\n    action: aws:executeAwsApi\n    description: |\n      ## EnableKeyRotation\n      Enables automatic key rotation for the given AWS KMS CMK.\n      ## Outputs\n      * EnableKeyRotationResponse: The standard HTTP response from the EnableKeyRotation API.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: kms\n      Api: EnableKeyRotation\n      KeyId: \"{{ KeyId }}\"\n    outputs:\n      - Name: EnableKeyRotationResponse\n        Selector: $\n        Type: StringMap\n  -\n    name: VerifyKeyRotation\n    action: \"aws:assertAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: true\n    description: |\n      ## VerifyKeyRotation\n      Verifies that the KeyRotationEnabled is set to true for the given AWS KMS CMK.\n    inputs:\n      Service: kms\n      Api: GetKeyRotationStatus\n      KeyId: \"{{ KeyId }}\"\n      PropertySelector: $.KeyRotationEnabled\n      DesiredValues:\n        - \"True\"\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableKeyRotation/Default"
   }
  },
  "SHARREnableRDSClusterDeletionProtection": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableRDSClusterDeletionProtection",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n   ### Document name - AWSConfigRemediation-EnableRDSClusterDeletionProtection\n\n   ## What does this document do?\n   This document enables `Deletion Protection` on a given Amazon RDS cluster using the [ModifyDBCluster](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_ModifyDBCluster.html) API.\n   Please note, AWS Config is required to be enabled in this region for this document to work as it requires the resource ID recorded by the AWS Config service.\n\n   ## Input Parameters\n   * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n   * ClusterId: (Required) Resource ID of the Amazon RDS cluster.\n\n   ## Output Parameters\n   * EnableRDSClusterDeletionProtection.ModifyDBClusterResponse: The standard HTTP response from the ModifyDBCluster API.\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  ClusterId:\n    type: String\n    description: (Required) Amazon RDS cluster resourceId for which deletion protection needs to be enabled.\n    allowedPattern: ^[a-zA-Z0-9-]{1,35}$\n\noutputs:\n  - EnableRDSClusterDeletionProtection.ModifyDBClusterResponse\nmainSteps:\n  -\n    name: GetRDSClusterIdentifer\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## GetRDSClusterIdentifer\n      Accepts the resource ID of the Amazon RDS Cluster as input and returns the cluster name.\n      ## Outputs\n      * DbClusterIdentifier: The ID of the DB cluster for which the input parameter matches DbClusterResourceId element from the output of the DescribeDBClusters API call.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: config\n      Api: GetResourceConfigHistory\n      resourceId: \"{{ ClusterId }}\"\n      resourceType: \"AWS::RDS::DBCluster\"\n      limit: 1\n    outputs:\n      - Name: DbClusterIdentifier\n        Selector: $.configurationItems[0].resourceName\n        Type: String\n  -\n    name: VerifyDBClusterStatus\n    action: \"aws:assertAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: false\n    description: |\n      ## VerifyDBClusterStatus\n      Verifies if the DB Cluster status is available before enabling cluster deletion protection.\n    inputs:\n      Service: rds\n      Api: DescribeDBClusters\n      DBClusterIdentifier: \"{{ GetRDSClusterIdentifer.DbClusterIdentifier }}\"\n      PropertySelector: \"$.DBClusters[0].Status\"\n      DesiredValues:\n        - \"available\"\n  -\n    name: EnableRDSClusterDeletionProtection\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## EnableRDSClusterDeletionProtection\n      Enables deletion protection on the Amazon RDS Cluster.\n      ## Outputs\n      * ModifyDBClusterResponse: The standard HTTP response from the ModifyDBCluster API.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n       Service: rds\n       Api: ModifyDBCluster\n       DBClusterIdentifier: \"{{ GetRDSClusterIdentifer.DbClusterIdentifier }}\"\n       DeletionProtection: True\n    outputs:\n      - Name: ModifyDBClusterResponse\n        Selector: $\n        Type: StringMap\n  -\n    name: VerifyDBClusterModification\n    action: \"aws:assertAwsResourceProperty\"\n    description: |\n      ## VerifyDBClusterModification\n      Verifies that deletion protection has been enabled for the given Amazon RDS database cluster.\n    timeoutSeconds: 600\n    isEnd: true\n    inputs:\n       Service: rds\n       Api: DescribeDBClusters\n       DBClusterIdentifier: \"{{ GetRDSClusterIdentifer.DbClusterIdentifier }}\"\n       PropertySelector: \"$.DBClusters[0].DeletionProtection\"\n       DesiredValues:\n         - \"True\"\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableRDSClusterDeletionProtection/Default"
   }
  },
  "SHARREnableCopyTagsToSnapshotOnRDSCluster": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableCopyTagsToSnapshotOnRDSCluster",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n  ### Document name - AWSConfigRemediation-EnableCopyTagsToSnapshotOnRDSCluster\n\n  ## What does this document do?\n  The document enables CopyTagsToSnapshot on an Amazon RDS cluster using the [ModifyDBCluster API](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_ModifyDBCluster.html).  Please note, AWS Config is required to be enabled in this region for this document to work as it requires the Resource ID recorded by the AWS Config service.\n\n  ## Input Parameters\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * DbClusterResourceId: (Required) Resource ID of the Amazon RDS Cluster for which CopyTagsToSnapshot needs to be enabled.\n  * ApplyImmediately: (Optional) A value that indicates whether the modifications in this request and any pending modifications are asynchronously applied as soon as possible, regardless of the PreferredMaintenanceWindow setting for the DB instance. By default, this parameter is disabled.\n    * Default: false\n\n  ## Output Parameters\n  * ModifyDBClusterResponse.Output: The response of the ModifyDBCluster API call.\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  DbClusterResourceId:\n    type: String\n    description: (Required) Resource ID of the Amazon RDS Cluster for which CopyTagsToSnapshot needs to be enabled.\n    allowedPattern: '^cluster-[A-Z0-9]+$'\n  ApplyImmediately:\n    type: Boolean\n    description: (Optional) A value that indicates whether the modifications in this request and any pending modifications are asynchronously applied as soon as possible, regardless of the PreferredMaintenanceWindow setting for the DB instance.  By default, this parameter is disabled.\n    default: false\n\noutputs:\n  - EnableCopyTagsToSnapshot.Output\nmainSteps:\n- name: GetDBClusterIdentifier\n  action: aws:executeAwsApi\n  description: |\n    ## GetDBClusterIdentifier\n    Accepts the Resource ID as input and returns the DB cluster identifier.\n    ## Outputs\n    * DBClusterIdentifier: The ID of the DB cluster.\n  timeoutSeconds: 600\n  isEnd: false\n  inputs:\n    Service: config\n    Api: GetResourceConfigHistory\n    resourceId: \"{{ DbClusterResourceId }}\"\n    resourceType: AWS::RDS::DBCluster\n  outputs:\n    - Name: DBClusterIdentifier\n      Selector: $.configurationItems[0].resourceName\n      Type: String\n- name: VerifyStatus\n  action: aws:assertAwsResourceProperty\n  description: |\n    ## VerifyStatus\n    Verifies if `Status` is available before proeeding to the next step.\n  timeoutSeconds: 600\n  isEnd: false\n  inputs:\n    Service: rds\n    Api: DescribeDBClusters\n    DBClusterIdentifier: \"{{ GetDBClusterIdentifier.DBClusterIdentifier }}\"\n    PropertySelector: $.DBClusters[0].Status\n    DesiredValues:\n      - \"available\"\n- name: EnableCopyTagsToSnapshot\n  action: aws:executeAwsApi\n  description: |\n    ## EnableCopyTagsToSnapshot\n    Accepts the cluster name as input and modifies it to set true for `CopyTagsToSnapshot`.\n    ## Outputs\n    * Output: Response from the ModifyDBCluster API call.\n  timeoutSeconds: 600\n  isEnd: false\n  inputs:\n    Service: rds\n    Api: ModifyDBCluster\n    DBClusterIdentifier: \"{{ GetDBClusterIdentifier.DBClusterIdentifier }}\"\n    ApplyImmediately: \"{{ ApplyImmediately }}\"\n    CopyTagsToSnapshot: True\n  outputs:\n    - Name: Output\n      Selector: $\n      Type: StringMap\n- name: VerifyDBClusterCopyTagsToSnapshotEnabled\n  action: aws:assertAwsResourceProperty\n  description: |\n    ## VerifyDBClusterCopyTagsToSnapshotEnabled\n    Verifies that `CopyTagsToSnapshot` has been enabled on the target resource.\n    ## Outputs\n    * Output: A success message or failure exception.\n  timeoutSeconds: 600\n  isEnd: true\n  inputs:\n    Service: rds\n    Api: DescribeDBClusters\n    DBClusterIdentifier: \"{{ GetDBClusterIdentifier.DBClusterIdentifier }}\"\n    PropertySelector: $.DBClusters[0].CopyTagsToSnapshot\n    DesiredValues:\n      - \"True\"\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableCopyTagsToSnapshotOnRDSCluster/Default"
   }
  },
  "SHARREnableRDSInstanceDeletionProtection": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableRDSInstanceDeletionProtection",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n  ### Document Name - SHARR-EnableRDSInstanceDeletionProtection\n\n  ## What does this document do?\n  This document enables `Deletion Protection` on a given Amazon RDS instance using the [ModifyDBInstance](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_ModifyDBInstance.html) API.\n\n  ## Input Parameters\n  * ApplyImmediately: (Optional) A value that indicates whether the modifications in this request and any pending modifications\n    are asynchronously applied as soon as possible, regardless of the PreferredMaintenanceWindow setting for the DB instance.\n    * Default: \"false\"\n  * DbInstanceResourceId: (Required) Amazon RDS Instance resourceId for which deletion protection needs to be enabled.\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n\n  ## Output Parameters\n  * EnableRDSInstanceDeletionProtection.ModifyDBInstanceResponse - The standard HTTP response from the ModifyDBInstance API.\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  ApplyImmediately:\n    type: Boolean\n    description: (Optional) A value that indicates whether the modifications in this request and any pending modifications are asynchronously applied as soon as possible, regardless of the PreferredMaintenanceWindow setting for the DB instance.\n    default: false\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  DbInstanceResourceId:\n    type: String\n    description: (Required) Resource ID of the Amazon RDS instance for which deletion protection needs to be enabled.\n    allowedPattern: \"^db-[A-Z0-9]{26}$\"\noutputs:\n  - EnableRDSInstanceDeletionProtection.ModifyDBInstanceResponse\nmainSteps:\n  -\n    name: GetRDSInstanceIdentifier\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## GetRDSInstanceIdentifier\n      Makes DescribeDBInstances API call using Amazon RDS Instance DbiResourceId to get DBInstance Identifier.\n      ## Outputs\n      * DbInstanceIdentifier: DBInstance Identifier of the Amazon RDS Instance.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      Filters:\n        - Name: \"dbi-resource-id\"\n          Values:\n            - \"{{ DbInstanceResourceId }}\"\n    outputs:\n      - Name: DbInstanceIdentifier\n        Selector: $.DBInstances[0].DBInstanceIdentifier\n        Type: String\n  -\n    name: EnableRDSInstanceDeletionProtection\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## EnableRDSInstanceDeletionProtection\n      Makes ModifyDBInstance API call to enable deletion protection on the Amazon RDS Instance using the DBInstanceId from the previous action.\n      ## Outputs\n      * DbInstance: The standard HTTP response from the ModifyDBInstance API.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: rds\n      Api: ModifyDBInstance\n      ApplyImmediately: \"{{ ApplyImmediately }}\"\n      DBInstanceIdentifier: \"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\"\n      DeletionProtection: True\n    outputs:\n      - Name: ModifyDBInstanceResponse\n        Selector: $\n        Type: StringMap\n  -\n    name: VerifyDBInstanceModification\n    action: \"aws:assertAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: true\n    description: |\n      ## VerifyDBInstanceModification\n      Checks whether deletion protection is enabled on Amazon RDS Instance.\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      DBInstanceIdentifier: \"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\"\n      PropertySelector: \"$.DBInstances[0].DeletionProtection\"\n      DesiredValues:\n        - \"True\"\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableRDSInstanceDeletionProtection/Default"
   }
  },
  "SHARREnableMultiAZOnRDSInstance": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableMultiAZOnRDSInstance",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n   ### Document name - SHARR-EnableMultiAZOnRDSInstance\n\n   ## What does this document do?\n   This document enables MultiAZ on an RDS instance.\n\n   ## Input Parameters\n   * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n   * DbiResourceId: (Required) Resource ID of the RDS instance to be modified.\n   * ApplyImmediately: (Optional) The MultiAZ on an RDS instance change is applied during the next maintenance window unless the ApplyImmediately parameter is enabled (true) for this request. By default, this parameter is disabled (false).\n\n   ## Output Parameters\n   * EnableMultiAZ.DBInstance: The standard HTTP response from the ModifyDBInstance API.\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  DbiResourceId:\n    type: String\n    description: (Required) Resource ID of the RDS instance for which MultiAZ needs to be enabled.\n    allowedPattern: ^db-[A-Z0-9]{26}$\n  ApplyImmediately:\n    type: Boolean\n    description: (Optional) MultiAZ on an RDS instance change is applied during the next maintenance window unless the ApplyImmediately parameter is enabled (true) for this request. By default, this parameter is disabled (false).\n    default: False\n    allowedValues:\n      - True\n      - False\n\noutputs:\n  - EnableMultiAZ.DBInstance\nmainSteps:\n  -\n    name: DescribeDBInstances\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## DescribeDBInstances\n      Makes DescribeDBInstances API call using RDS DB instance resource identifiers to get DBInstanceIdentifier.\n      ## Outputs\n      * DBInstanceIdentifier: DBInstance identifier of the RDS instance.\n      * MultiAZ: MultiAZ state of the RDS instance.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      Filters:\n        - Name: \"dbi-resource-id\"\n          Values:\n            - \"{{ DbiResourceId }}\"\n    outputs:\n      - Name: DBInstanceIdentifier\n        Selector: $.DBInstances[0].DBInstanceIdentifier\n        Type: String\n      - Name: MultiAZ\n        Selector: $.DBInstances[0].MultiAZ\n        Type: Boolean\n\n  -\n    name: VerifyDBInstanceStatus\n    action: \"aws:assertAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: false\n    description: |\n      ## VerifyDBInstanceStatus\n      Verifies if DB instance status is available before enabling MultiAZ.\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      DBInstanceIdentifier: \"{{ DescribeDBInstances.DBInstanceIdentifier }}\"\n      PropertySelector: \"$.DBInstances[0].DBInstanceStatus\"\n      DesiredValues:\n        - \"available\"\n\n  -\n    name: EndIfMultiAZAlreadyEnabled\n    action: aws:branch\n    description: |\n      ## EndIfMultiAZAlreadyEnabled\n      Checks if MultiAZ is not enabled on the DB instance. If not enabled, proceed with EnableMultiAZ step. Otherwise, end the flow.\n    inputs:\n      Choices:\n      - NextStep: EnableMultiAZ\n        Variable: \"{{ DescribeDBInstances.MultiAZ }}\"\n        BooleanEquals: false\n    isEnd: true\n\n  -\n    name: EnableMultiAZ\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## EnableMultiAZ\n      Makes ModifyDBInstance API call to enable MultiAZ on the RDS instance using the DBInstanceIdentifier from the previous step and MultiAZ as true.\n      ## Outputs\n      * DBInstance: The standard HTTP response from the ModifyDBInstance API.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: rds\n      Api: ModifyDBInstance\n      DBInstanceIdentifier: \"{{ DescribeDBInstances.DBInstanceIdentifier }}\"\n      MultiAZ: True\n      ApplyImmediately: \"{{ ApplyImmediately }}\"\n    outputs:\n      - Name: DBInstance\n        Selector: $\n        Type: StringMap\n\n  -\n    name: VerifyMultiAZEnabled\n    action: \"aws:assertAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: true\n    description: |\n      ## VerifyMultiAZEnabled\n      Verifies that the RDS Instance's `PendingModifiedValues.MultiAZ` value is `True`.\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      DBInstanceIdentifier: \"{{ DescribeDBInstances.DBInstanceIdentifier }}\"\n      PropertySelector: \"$.DBInstances[0].PendingModifiedValues.MultiAZ\"\n      DesiredValues:\n        - \"True\"\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableMultiAZOnRDSInstance/Default"
   }
  },
  "SHARRRemoveVPCDefaultSecurityGroupRules": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-RemoveVPCDefaultSecurityGroupRules",
    "Content": "description: |\n  ### Document name - AWSConfigRemediation-RemoveVPCDefaultSecurityGroupRules\n\n  ## What does this document do?\n  This document removes all inbound and outbound rules from the default security group in an Amazon VPC. A default security group is defined as any security group whose name is `default`. If the security group ID passed to this automation document belongs to a non-default security group, this document does not perform any changes to the AWS account.\n\n  ## Input Parameters\n  * GroupId: (Required) The unique ID of the security group.\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n\n  ## Output Parameters\n  * RemoveRulesAndVerify.Output - Success message or failure exception.\n\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  GroupId:\n    type: String\n    description: (Required) The unique ID of the security group.\n    allowedPattern: \"sg-[a-z0-9]+$\"\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n\noutputs:\n  - RemoveRulesAndVerify.Output\n\nmainSteps:\n  - name: CheckDefaultSecurityGroup\n    action: aws:assertAwsResourceProperty\n    isCritical: True\n    onFailure: Abort\n    maxAttempts: 3\n    timeoutSeconds: 20\n    description: |\n      ## CheckDefaultSecurityGroup\n      Verifies that the security group name does match `default`. If the group name does match `default`, go to the next step: DescribeSecurityGroups.\n    inputs:\n      Service: ec2\n      Api: DescribeSecurityGroups\n      GroupIds:\n        - \"{{ GroupId }}\"\n      PropertySelector: \"$.SecurityGroups[0].GroupName\"\n      DesiredValues:\n        - \"default\"\n    nextStep: RemoveRulesAndVerify\n\n  - name: RemoveRulesAndVerify\n    action: \"aws:executeScript\"\n    isCritical: True\n    onFailure: Abort\n    maxAttempts: 3\n    timeoutSeconds: 180\n    isEnd: true\n    description: |\n      ## RemoveRulesAndVerify\n      Removes all rules from the default security group.\n      ## Outputs\n      * Output: Success message or failure exception.\n    inputs:\n      Runtime: python3.8\n      Handler: handler\n      InputPayload:\n        GroupId: \"{{ GroupId }}\"\n      Script: |-\n        import boto3\n        from botocore.exceptions import ClientError\n        from time import sleep\n\n\n        ec2_client = boto3.client(\"ec2\")\n\n\n        def get_permissions(group_id):\n            default_group = ec2_client.describe_security_groups(GroupIds=[group_id]).get(\"SecurityGroups\")[0]\n            return default_group.get(\"IpPermissions\"), default_group.get(\"IpPermissionsEgress\")\n\n\n        def handler(event, context):\n            group_id = event.get(\"GroupId\")\n            ingress_permissions, egress_permissions = get_permissions(group_id)\n\n            if ingress_permissions:\n                ec2_client.revoke_security_group_ingress(GroupId=group_id, IpPermissions=ingress_permissions)\n            if egress_permissions:\n                ec2_client.revoke_security_group_egress(GroupId=group_id, IpPermissions=egress_permissions)\n\n            ingress_permissions, egress_permissions = get_permissions(group_id)\n            if ingress_permissions or egress_permissions:\n                raise Exception(f\"VERIFICATION FAILED. SECURITY GROUP {group_id} NOT CLOSED.\")\n\n            return {\n                \"output\": \"Security group closed successfully.\"\n            }\n    outputs:\n      - Name: Output\n        Selector: $.Payload.output\n        Type: String\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR RemoveVPCDefaultSecurityGroupRules/Default"
   }
  },
  "SHARRRevokeUnusedIAMUserCredentials": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-RevokeUnusedIAMUserCredentials",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n   ### Document Name - AWSConfigRemediation-RevokeUnusedIAMUserCredentials\n\n   ## What does this document do?\n   This document revokes unused IAM passwords and active access keys. This document will deactivate expired access keys by using the [UpdateAccessKey API](https://docs.aws.amazon.com/IAM/latest/APIReference/API_UpdateAccessKey.html) and delete expired login profiles by using the [DeleteLoginProfile API](https://docs.aws.amazon.com/IAM/latest/APIReference/API_DeleteLoginProfile.html). Please note, this automation document requires AWS Config to be enabled.\n\n   ## Input Parameters\n   * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n   * IAMResourceId: (Required) IAM resource unique identifier.\n   * MaxCredentialUsageAge: (Required) Maximum number of days within which a credential must be used. The default value is 90 days.\n\n   ## Output Parameters\n   * RevokeUnusedIAMUserCredentialsAndVerify.Output - Success message or failure Exception.\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  IAMResourceId:\n    type: String\n    description: (Required) IAM resource unique identifier.\n    allowedPattern: ^[\\w+=,.@_-]{1,128}$\n  MaxCredentialUsageAge:\n    type: String\n    description: (Required) Maximum number of days within which a credential must be used. The default value is 90 days.\n    allowedPattern: ^(\\b([0-9]|[1-8][0-9]|9[0-9]|[1-8][0-9]{2}|9[0-8][0-9]|99[0-9]|[1-8][0-9]{3}|9[0-8][0-9]{2}|99[0-8][0-9]|999[0-9]|10000)\\b)$\n    default: \"90\"\noutputs:\n  - RevokeUnusedIAMUserCredentialsAndVerify.Output\nmainSteps:\n  - name: RevokeUnusedIAMUserCredentialsAndVerify\n    action: aws:executeScript\n    timeoutSeconds: 600\n    isEnd: true\n    description: |\n      ## RevokeUnusedIAMUserCredentialsAndVerify\n      This step deactivates expired IAM User access keys, deletes expired login profiles and verifies credentials were revoked\n      ## Outputs\n      * Output: Success message or failure Exception.\n    inputs:\n      Runtime: python3.8\n      Handler: unused_iam_credentials_handler\n      InputPayload:\n        IAMResourceId: \"{{ IAMResourceId }}\"\n        MaxCredentialUsageAge: \"{{ MaxCredentialUsageAge }}\"\n      Script: |-\n        import boto3\n        from datetime import datetime\n        from datetime import timedelta\n\n        iam_client = boto3.client(\"iam\")\n        config_client = boto3.client(\"config\")\n\n        responses = {}\n        responses[\"DeactivateUnusedKeysResponse\"] = []\n\n        def list_access_keys(user_name):\n          return iam_client.list_access_keys(UserName=user_name).get(\"AccessKeyMetadata\")\n\n        def deactivate_key(user_name, access_key):\n          responses[\"DeactivateUnusedKeysResponse\"].append({\"AccessKeyId\": access_key, \"Response\": iam_client.update_access_key(UserName=user_name, AccessKeyId=access_key, Status=\"Inactive\")})\n\n        def deactivate_unused_keys(access_keys, max_credential_usage_age, user_name):\n          for key in access_keys:\n            last_used = iam_client.get_access_key_last_used(AccessKeyId=key.get(\"AccessKeyId\")).get(\"AccessKeyLastUsed\")\n            if last_used.get(\"LastUsedDate\"):\n              last_used_date = last_used.get(\"LastUsedDate\").replace(tzinfo=None)\n              last_used_days = (datetime.now() - last_used_date).days\n              if last_used_days >= max_credential_usage_age:\n                deactivate_key(user_name, key.get(\"AccessKeyId\"))\n            else:\n              create_date = key.get(\"CreateDate\").replace(tzinfo=None)\n              days_since_creation = (datetime.now() - create_date).days\n              if days_since_creation >= max_credential_usage_age:\n                deactivate_key(user_name, key.get(\"AccessKeyId\"))\n\n        def get_login_profile(user_name):\n          try:\n            return iam_client.get_login_profile(UserName=user_name)[\"LoginProfile\"]\n          except iam_client.exceptions.NoSuchEntityException:\n            return False\n\n        def delete_unused_password(user_name, max_credential_usage_age):\n          user = iam_client.get_user(UserName=user_name).get(\"User\")\n          password_last_used_days = 0\n          login_profile = get_login_profile(user_name)\n          if login_profile and user.get(\"PasswordLastUsed\"):\n            password_last_used = user.get(\"PasswordLastUsed\").replace(tzinfo=None)\n            password_last_used_days = (datetime.now() - password_last_used).days\n          elif login_profile and not user.get(\"PasswordLastUsed\"):\n            password_creation_date = login_profile.get(\"CreateDate\").replace(tzinfo=None)\n            password_last_used_days = (datetime.now() - password_creation_date).days\n          if password_last_used_days >= max_credential_usage_age:\n            responses[\"DeleteUnusedPasswordResponse\"] = iam_client.delete_login_profile(UserName=user_name)\n\n        def verify_expired_credentials_revoked(responses, user_name):\n          if responses.get(\"DeactivateUnusedKeysResponse\"):\n            for key in responses.get(\"DeactivateUnusedKeysResponse\"):\n              key_data = next(filter(lambda x: x.get(\"AccessKeyId\") == key.get(\"AccessKeyId\"), list_access_keys(user_name)))\n              if key_data.get(\"Status\") != \"Inactive\":\n                error_message = \"VERIFICATION FAILED. ACCESS KEY {} NOT DEACTIVATED\".format(key_data.get(\"AccessKeyId\"))\n                raise Exception(error_message)\n          if responses.get(\"DeleteUnusedPasswordResponse\"):\n            try:\n              iam_client.get_login_profile(UserName=user_name)\n              error_message = \"VERIFICATION FAILED. IAM USER {} LOGIN PROFILE NOT DELETED\".format(user_name)\n              raise Exception(error_message)\n            except iam_client.exceptions.NoSuchEntityException:\n              pass\n          return {\n              \"output\": \"Verification of unused IAM User credentials is successful.\",\n              \"http_responses\": responses\n          }\n\n        def get_user_name(resource_id):\n          list_discovered_resources_response = config_client.list_discovered_resources(\n              resourceType='AWS::IAM::User',\n              resourceIds=[resource_id]\n          )\n          resource_name = list_discovered_resources_response.get(\"resourceIdentifiers\")[0].get(\"resourceName\")\n          return resource_name\n\n        def unused_iam_credentials_handler(event, context):\n          iam_resource_id = event.get(\"IAMResourceId\")\n          user_name = get_user_name(iam_resource_id)\n\n          max_credential_usage_age = int(event.get(\"MaxCredentialUsageAge\"))\n\n          access_keys = list_access_keys(user_name)\n          unused_keys = deactivate_unused_keys(access_keys, max_credential_usage_age, user_name)\n\n          delete_unused_password(user_name, max_credential_usage_age)\n\n          return verify_expired_credentials_revoked(responses, user_name)\n    outputs:\n      - Name: Output\n        Selector: $.Payload\n        Type: StringMap\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR RevokeUnusedIAMUserCredentials/Default"
   }
  },
  "SHARRSetIAMPasswordPolicy": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-SetIAMPasswordPolicy",
    "Content": "description: |\n  ### Document name - AWSConfigRemediation-SetIAMPasswordPolicy\n\n  ## What does this document do?\n  This document sets the AWS Identity and Access Management (IAM) user password policy for the AWS account using the [UpdateAccountPasswordPolicy](https://docs.aws.amazon.com/IAM/latest/APIReference/API_UpdateAccountPasswordPolicy.html) API.\n\n  ## Input Parameters\n  * AllowUsersToChangePassword: (Optional) Allows all IAM users in your account to use the AWS Management Console to change their own passwords.\n  * HardExpiry: (Optional) Prevents IAM users from setting a new password after their password has expired.\n  * MaxPasswordAge: (Optional) The number of days that an IAM user password is valid.\n  * MinimumPasswordLength: (Optional) The minimum number of characters allowed in an IAM user password.\n  * PasswordReusePrevention: (Optional) Specifies the number of previous passwords that IAM users are prevented from reusing.\n  * RequireLowercaseCharacters: (Optional) Specifies whether IAM user passwords must contain at least one lowercase character from the ISO basic Latin alphabet (a to z).\n  * RequireNumbers: (Optional) Specifies whether IAM user passwords must contain at least one numeric character (0 to 9).\n  * RequireSymbols: (Optional) pecifies whether IAM user passwords must contain at least one of the following non-alphanumeric characters :! @ \\# $ % ^ * ( ) _ + - = [ ] { } | '\n  * RequireUppercaseCharacters: (Optional) Specifies whether IAM user passwords must contain at least one uppercase character from the ISO basic Latin alphabet (A to Z).\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  ## Output Parameters\n  * UpdateAndVerifyIamUserPasswordPolicy.Output\nschemaVersion: \"0.3\"\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  AllowUsersToChangePassword:\n    type: Boolean\n    description: (Optional) Allows all IAM users in your AWS account to use the AWS Management Console to change their own passwords.\n    default: false\n  HardExpiry:\n    type: Boolean\n    description: (Optional) Prevents IAM users from setting a new password after their password has expired.\n    default: false\n  MaxPasswordAge:\n    type: Integer\n    description: (Optional) The number of days that an IAM user password is valid.\n    allowedPattern: ^\\d{0,3}$|^10[0-8]\\d$|^109[0-5]$\n    default: 0\n  MinimumPasswordLength:\n    type: Integer\n    description: (Optional) The minimum number of characters allowed in an IAM user password.\n    allowedPattern: ^[6-9]$|^[1-9]\\d$|^1[01]\\d$|^12[0-8]$\n    default: 6\n  PasswordReusePrevention:\n    type: Integer\n    description: (Optional) Specifies the number of previous passwords that IAM users are prevented from reusing.\n    allowedPattern: ^\\d{0,1}$|^1\\d$|^2[0-4]$\n    default: 0\n  RequireLowercaseCharacters:\n    type: Boolean\n    description: (Optional) Specifies whether IAM user passwords must contain at least one lowercase character from the ISO basic Latin alphabet (a to z).\n    default: false\n  RequireNumbers:\n    type: Boolean\n    description: (Optional) Specifies whether IAM user passwords must contain at least one numeric character (0 to 9).\n    default: false\n  RequireSymbols:\n    type: Boolean\n    description: (Optional) Specifies whether IAM user passwords must contain at least one of the following non-alphanumeric characters :! @ \\# $ % ^ * ( ) _ + - = [ ] { } | '.\n    default: false\n  RequireUppercaseCharacters:\n    type: Boolean\n    description: (Optional) Specifies whether IAM user passwords must contain at least one uppercase character from the ISO basic Latin alphabet (A to Z).\n    default: false\noutputs:\n  - UpdateAndVerifyIamUserPasswordPolicy.Output\nmainSteps:\n  - name: UpdateAndVerifyIamUserPasswordPolicy\n    action: \"aws:executeScript\"\n    timeoutSeconds: 600\n    isEnd: true\n    description: |\n      ## UpdateAndVerifyIamUserPasswordPolicy\n      Sets or updates the AWS account password policy using input parameters using UpdateAccountPasswordPolicy API.\n      Verify AWS account password policy using GetAccountPasswordPolicy API.\n      ## Outputs\n      * Output: Success message with HTTP Response from GetAccountPasswordPolicy API call or failure exception.\n    inputs:\n      Runtime: python3.8\n      Handler: update_and_verify_iam_user_password_policy\n      InputPayload:\n        AllowUsersToChangePassword: \"{{ AllowUsersToChangePassword }}\"\n        HardExpiry: \"{{ HardExpiry }}\"\n        MaxPasswordAge: \"{{ MaxPasswordAge }}\"\n        MinimumPasswordLength: \"{{ MinimumPasswordLength }}\"\n        PasswordReusePrevention: \"{{ PasswordReusePrevention }}\"\n        RequireLowercaseCharacters: \"{{ RequireLowercaseCharacters }}\"\n        RequireNumbers: \"{{ RequireNumbers }}\"\n        RequireSymbols: \"{{ RequireSymbols }}\"\n        RequireUppercaseCharacters: \"{{ RequireUppercaseCharacters }}\"\n      Script: |-\n        import boto3\n\n\n        def update_and_verify_iam_user_password_policy(event, context):\n            iam_client = boto3.client('iam')\n\n            try:\n                params = dict()\n                params[\"AllowUsersToChangePassword\"] = event[\"AllowUsersToChangePassword\"]\n                if \"HardExpiry\" in event:\n                    params[\"HardExpiry\"] = event[\"HardExpiry\"]\n                if event[\"MaxPasswordAge\"]:\n                    params[\"MaxPasswordAge\"] = event[\"MaxPasswordAge\"]\n                if event[\"PasswordReusePrevention\"]:\n                    params[\"PasswordReusePrevention\"] = event[\"PasswordReusePrevention\"]\n                params[\"MinimumPasswordLength\"] = event[\"MinimumPasswordLength\"]\n                params[\"RequireLowercaseCharacters\"] = event[\"RequireLowercaseCharacters\"]\n                params[\"RequireNumbers\"] = event[\"RequireNumbers\"]\n                params[\"RequireSymbols\"] = event[\"RequireSymbols\"]\n                params[\"RequireUppercaseCharacters\"] = event[\"RequireUppercaseCharacters\"]\n\n                update_api_response = iam_client.update_account_password_policy(**params)\n\n                # Verifies IAM Password Policy configuration for AWS account using GetAccountPasswordPolicy() api call.\n                response = iam_client.get_account_password_policy()\n                if all([response[\"PasswordPolicy\"][\"AllowUsersToChangePassword\"] == event[\"AllowUsersToChangePassword\"],\n                        response[\"PasswordPolicy\"][\"MinimumPasswordLength\"] == event[\"MinimumPasswordLength\"],\n                        response[\"PasswordPolicy\"][\"RequireLowercaseCharacters\"] == event[\"RequireLowercaseCharacters\"],\n                        response[\"PasswordPolicy\"][\"RequireNumbers\"] == event[\"RequireNumbers\"],\n                        response[\"PasswordPolicy\"][\"RequireUppercaseCharacters\"] == event[\"RequireUppercaseCharacters\"],\n                        ((response[\"PasswordPolicy\"][\"HardExpiry\"] == event[\"HardExpiry\"]) if \"HardExpiry\" in event else True),\n                        ((response[\"PasswordPolicy\"][\"MaxPasswordAge\"] == event[\"MaxPasswordAge\"]) if event[\"MaxPasswordAge\"] else True),\n                        ((response[\"PasswordPolicy\"][\"PasswordReusePrevention\"] == event[\"PasswordReusePrevention\"]) if event[\"PasswordReusePrevention\"] else True)]):\n                    return {\n                        \"output\": {\n                            \"Message\": \"AWS Account Password Policy setting is SUCCESSFUL.\",\n                            \"UpdatePolicyHTTPResponse\": update_api_response,\n                            \"GetPolicyHTTPResponse\": response\n                        }\n                    }\n                raise Exception(\"VERIFICATION FAILED. AWS ACCOUNT PASSWORD POLICY NOT UPDATED.\")\n\n            except iam_client.exceptions.NoSuchEntityException:\n                raise Exception(\"VERIFICATION FAILED. UNABLE TO UPDATE AWS ACCOUNT PASSWORD POLICY.\")\n\n    outputs:\n      - Name: Output\n        Selector: $.Payload.output\n        Type: StringMap\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR SetIAMPasswordPolicy/Default"
   }
  },
  "SHARRDisablePublicAccessToRDSInstance": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-DisablePublicAccessToRDSInstance",
    "Content": "schemaVersion: \"0.3\"\ndescription: |\n   ### Document name - AWSConfigRemediation-DisablePublicAccessToRDSInstance\n\n   ## What does this document do?\n   The runbook disables public accessibility for the Amazon RDS database instance you specify using\n   the [ModifyDBInstance](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_ModifyDBInstance.html) API.\n\n   ## Input Parameters\n   * AutomationAssumeRole: (Required) The Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role that allows Systems Manager Automation to perform the actions on your behalf.\n   * DbiResourceId: (Required) The resource identifier for the DB instance you want to disable public accessibility.\n\n   ## Output Parameters\n   * DisablePubliclyAccessibleOnRDS.Response: The standard HTTP response from the ModifyDBInstance API.\n\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  DbiResourceId:\n    type: String\n    description: (Required) The resource identifier for the DB instance you want to disable public accessibility.\n    allowedPattern: \"db-[A-Z0-9]{26}\"\noutputs:\n  - DisablePubliclyAccessibleOnRDS.Response\nmainSteps:\n  -\n    name: GetRDSInstanceIdentifier\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## GetRDSInstanceIdentifier\n      Gathers the DB instance identifier from the DB instance resource identifier.\n      ## Outputs\n      * DbInstanceIdentifier: The Amazon RDS DB instance identifier.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      Filters:\n        - Name: \"dbi-resource-id\"\n          Values:\n            - \"{{ DbiResourceId }}\"\n    outputs:\n      - Name: DbInstanceIdentifier\n        Selector: $.DBInstances[0].DBInstanceIdentifier\n        Type: String\n  -\n    name: VerifyDBInstanceStatus\n    action: \"aws:assertAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: false\n    description: |\n      ## VerifyDBInstanceStatus\n      Verifies the DB instances is in an AVAILABLE state.\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      DBInstanceIdentifier: \"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\"\n      PropertySelector: \"$.DBInstances[0].DBInstanceStatus\"\n      DesiredValues:\n        - \"available\"\n  -\n    name: DisablePubliclyAccessibleOnRDS\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## DisablePubliclyAccessibleOnRDS\n      Disables public accessibility on your DB instance.\n      ## Outputs\n      * Response: The standard HTTP response from the ModifyDBInstance API.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n       Service: rds\n       Api: ModifyDBInstance\n       DBInstanceIdentifier: \"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\"\n       PubliclyAccessible: false\n    outputs:\n      - Name: Response\n        Selector: $\n        Type: StringMap\n  -\n    name: WaitForDBInstanceStatusToModify\n    action: \"aws:waitForAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: false\n    description: |\n      ## WaitForDBInstanceStatusToModify\n      Waits for the DB instance to change to a MODIFYING state.\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      DBInstanceIdentifier: \"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\"\n      PropertySelector: \"$.DBInstances[0].DBInstanceStatus\"\n      DesiredValues:\n        - \"modifying\"\n  -\n    name: WaitForDBInstanceStatusToAvailableAfterModify\n    action: \"aws:waitForAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: false\n    description: |\n      ## WaitForDBInstanceStatusToAvailableAfterModify\n      Waits for the DB instance to change to an AVAILABLE state\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      DBInstanceIdentifier: \"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\"\n      PropertySelector: \"$.DBInstances[0].DBInstanceStatus\"\n      DesiredValues:\n        - \"available\"\n  -\n    name: VerifyDBInstancePubliclyAccess\n    action: \"aws:assertAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: true\n    description: |\n      ## VerifyDBInstancePubliclyAccess\n      Confirms public accessibility is disabled on the DB instance.\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      DBInstanceIdentifier: \"{{ GetRDSInstanceIdentifier.DbInstanceIdentifier }}\"\n      PropertySelector: \"$.DBInstances[0].PubliclyAccessible\"\n      DesiredValues:\n        - \"False\"\n\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR DisablePublicAccessToRDSInstance/Default"
   }
  },
  "SHARREnableMinorVersionUpgradeOnRDSDBInstance": {
   "Type": "Custom::UpdatableRunbook",
   "Properties": {
    "ServiceToken": {
     "Fn::Join": [
      "",
      [
       "arn:",
       {
        "Ref": "AWS::Partition"
       },
       ":lambda:",
       {
        "Ref": "AWS::Region"
       },
       ":",
       {
        "Ref": "AWS::AccountId"
       },
       ":function:SO0111-SHARR-updatableRunbookProvider"
      ]
     ]
    },
    "Name": "SHARR-EnableMinorVersionUpgradeOnRDSDBInstance",
    "Content": "\nschemaVersion: \"0.3\"\ndescription: |\n  ### Document name - AWSConfigRemediation-EnableMinorVersionUpgradeOnRDSDBInstance\n\n  ## What does this document do?\n  This document enables AutoMinorVersionUpgrade on the Amazon Relational Database Service (Amazon RDS) instance using the [ModifyDBInstance](https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_ModifyDBInstance.html) API.\n\n  ## Input parameters\n  * AutomationAssumeRole: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n  * DbiResourceId: (Required) Resource ID of the Amazon RDS instance to be modified.\n\n  ## Output parameters\n  * ModifyDBInstance.Output: The standard HTTP response from the ModifyDBInstance API.\nassumeRole: \"{{ AutomationAssumeRole }}\"\nparameters:\n  AutomationAssumeRole:\n    type: String\n    description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf.\n    allowedPattern: '^arn:(?:aws|aws-us-gov|aws-cn):iam::\\d{12}:role/[\\w+=,.@-]+$'\n  DbiResourceId:\n    type: String\n    description: (Required) Resource ID of the Amazon RDS instance for which AutoMinorVersionUpgrade needs to be enabled.\n    allowedPattern: \"^db-[A-Z0-9]{26}$\"\noutputs:\n  - ModifyDBInstance.Output\nmainSteps:\n  - name: GetRDSInstanceIdentifier\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## GetRDSInstanceIdentifier\n      Makes DescribeDBInstances API call using the database instance resource identifier to get DBInstanceIdentifier.\n      ## Outputs\n      * DBInstanceIdentifier: DBInstance identifier of the Amazon RDS instance.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      Filters:\n        - Name: dbi-resource-id\n          Values:\n            - \"{{ DbiResourceId }}\"\n    outputs:\n      - Name: DBInstanceIdentifier\n        Selector: \"$.DBInstances[0].DBInstanceIdentifier\"\n        Type: String\n  - name: VerifyDBInstanceStatus\n    action: \"aws:assertAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: false\n    description: |\n      ## VerifyDBInstanceStatus\n      Verifies whether AWS RDS DBInstance status is available before enabling AutoMiniorVersionUpgrade.\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      DBInstanceIdentifier: \"{{ GetRDSInstanceIdentifier.DBInstanceIdentifier }}\"\n      PropertySelector: \"$.DBInstances[0].DBInstanceStatus\"\n      DesiredValues:\n        - \"available\"\n  - name: ModifyDBInstance\n    action: \"aws:executeAwsApi\"\n    description: |\n      ## ModifyDBInstance\n      Makes ModifyDBInstance API call to enable AutoMinorVersionUpgrade on the Amazon RDS instance using the DBInstanceIdentifier.\n      ## Outputs\n      * Output: The standard HTTP response from the ModifyDBInstance API.\n    timeoutSeconds: 600\n    isEnd: false\n    inputs:\n      Service: rds\n      Api: ModifyDBInstance\n      DBInstanceIdentifier: \"{{ GetRDSInstanceIdentifier.DBInstanceIdentifier }}\"\n      AutoMinorVersionUpgrade: true\n    outputs:\n      - Name: Output\n        Selector: $\n        Type: StringMap\n  - name: VerifyDBInstanceState\n    action: \"aws:assertAwsResourceProperty\"\n    timeoutSeconds: 600\n    isEnd: true\n    description: |\n      ## VerifyDBInstanceState\n      Verifies the Amazon RDS Instance's \"AutoMinorVersionUpgrade\" property is set to \"True\".\n    inputs:\n      Service: rds\n      Api: DescribeDBInstances\n      DBInstanceIdentifier: \"{{ GetRDSInstanceIdentifier.DBInstanceIdentifier }}\"\n      PropertySelector: \"$.DBInstances[0].AutoMinorVersionUpgrade\"\n      DesiredValues:\n        - \"True\"\n",
    "DocumentFormat": "YAML",
    "DocumentType": "Automation"
   },
   "UpdateReplacePolicy": "Delete",
   "DeletionPolicy": "Delete",
   "Metadata": {
    "aws:cdk:path": "RunbookStack/SHARR EnableMinorVersionUpgradeOnRDSDBInstance/Default"
   }
  }
 }
}